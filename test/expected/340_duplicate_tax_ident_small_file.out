BEGIN;
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create(p_display_name => 'Test Admin', p_email => 'test.admin@statbus.org', p_statbus_role => 'admin_user'::statbus_role, p_password => 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Regular', p_email => 'test.regular@statbus.org', p_statbus_role => 'regular_user'::statbus_role, p_password => 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Restricted', p_email => 'test.restricted@statbus.org', p_statbus_role => 'restricted_user'::statbus_role, p_password => 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

CREATE OR REPLACE PROCEDURE test.remove_pg_temp_for_tx_user_switch(p_keep_tables text[] DEFAULT '{}')
LANGUAGE plpgsql
AS $remove_pg_temp_for_tx_user_switch$
DECLARE
    rec record;
    v_found_count integer := 0;
BEGIN
    RAISE DEBUG 'Running test.remove_pg_temp_for_tx_user_switch(p_keep_tables => %)...', p_keep_tables;
    -- Remove temporary cache tables used by import, as we switch user inside the *same* transaction,
    -- and the new user can not modify tables owned by the previous import.
    -- This generic loop cleans up all tables and views in the pg_temp schema, except those specified to keep.
    FOR rec IN
        SELECT
            c.relname,
            c.relkind
        FROM pg_catalog.pg_class AS c
        LEFT JOIN pg_catalog.pg_namespace AS n ON n.oid = c.relnamespace
        WHERE c.relkind IN ('r', 'p', 'v', 'm') AND n.oid = pg_my_temp_schema() -- r=table, p=partitioned, v=view, m=materialized
          AND c.relname <> ALL(p_keep_tables)
    LOOP
        v_found_count := v_found_count + 1;
        IF rec.relkind IN ('r', 'p', 'm') THEN
            RAISE DEBUG '  -> Dropping temp TABLE %', rec.relname;
            EXECUTE format('DROP TABLE IF EXISTS pg_temp.%I CASCADE', rec.relname);
        ELSIF rec.relkind = 'v' THEN
            RAISE DEBUG '  -> Dropping temp VIEW %', rec.relname;
            EXECUTE format('DROP VIEW IF EXISTS pg_temp.%I CASCADE', rec.relname);
        END IF;
    END LOOP;

    RAISE DEBUG '...finished test.remove_pg_temp_for_tx_user_switch(). Found and dropped % objects.', v_found_count;

    -- This procedure is part of the sql_saga extension and has its own cleanup logic.
    -- While the loop above handles tables/views, this call ensures any other temporary
    -- objects it creates are also cleaned up.
    CALL sql_saga.temporal_merge_drop_temp_tables();
END;
$remove_pg_temp_for_tx_user_switch$;
\echo "Setting up Statbus using the web provided examples"
"Setting up Statbus using the web provided examples"
-- A Super User configures statbus.
CALL test.set_user_from_email('test.admin@statbus.org');
\i samples/demo/getting-started.sql
-- Set the activity category standard to ISIC v4 for the demo data.
\echo "User selected the Activity Category Standard"
"User selected the Activity Category Standard"
INSERT INTO settings(activity_category_standard_id,country_id)
SELECT (SELECT id FROM activity_category_standard WHERE code = 'isic_v4')
     , (SELECT id FROM public.country WHERE iso_2 = 'UN')
ON CONFLICT (only_one_setting)
DO UPDATE SET
    activity_category_standard_id = EXCLUDED.activity_category_standard_id,
    country_id = EXCLUDED.country_id;
\echo "User uploads the demo activity categories"
"User uploads the demo activity categories"
\copy public.activity_category_available_custom(path,name) FROM 'app/public/demo/activity_custom_isic_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo regions"
"User uploads the demo regions"
\copy public.region_upload(path, name) FROM 'app/public/demo/regions_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo sectors"
"User uploads the demo sectors"
\copy public.sector_custom_only(path,name,description) FROM 'app/public/demo/sectors_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo legal forms"
"User uploads the demo legal forms"
\copy public.legal_form_custom_only(code,name) FROM 'app/public/demo/legal_forms_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
-- The demo data uses data sources that are part of the core database seed.
-- This file is included for structural consistency with other sample data sets.
SAVEPOINT before_loading_units;
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                0 |                0
(1 row)

-- Create Import Job for Legal Units
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment, time_context_ident)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_job_provided'),
    'import_340_lu_idents',
    'Import Legal Units Duplicate Idents (340_duplicate_tax_ident_small_file.sql)',
    'Import job for legal units from test/data/340_duplicate_tax_ident_small_file.csv using legal_unit_job_provided definition.',
    'Test data load (340_duplicate_tax_ident_small_file.sql)',
    'r_year_curr';
\echo "User uploads the legal units over time (via import job: import_340_lu_idents)"
"User uploads the legal units over time (via import job: import_340_lu_idents)"
\copy public.import_340_lu_idents_upload(name,stat_ident,tax_ident) FROM 'test/data/340_duplicate_tax_ident_small_file.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs
Run worker processing for import jobs
--SET client_min_messages TO DEBUG1;
CALL worker.process_tasks(p_queue => 'import');
--SET client_min_messages TO NOTICE;
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     3
 import    | completed |    47
(2 rows)

\echo "Checking unit counts after import processing"
"Checking unit counts after import processing"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                3 |                3
(1 row)

\echo "Inspecting import job data for import_340_lu_idents"
"Inspecting import job data for import_340_lu_idents"
SELECT row_id, state, errors, stat_ident_raw, name_raw, tax_ident_raw, merge_status
FROM public.import_340_lu_idents_data
ORDER BY row_id
LIMIT 5;
 row_id |   state   |                                       errors                                        | stat_ident_raw |         name_raw         | tax_ident_raw |       merge_status        
--------+-----------+-------------------------------------------------------------------------------------+----------------+--------------------------+---------------+---------------------------
      1 | processed | {}                                                                                  | 8204401        | NILE PEARL WATER         | 4672419       | {"legal_unit": "APPLIED"}
      2 | error     | {"tax_ident_raw": "Duplicate identifier: tax_ident=267777 appears in 2 rows: 2, 3"} | 92890834       | EQUATOR GLOBE SOLUTIONS  | 267777        | {}
      3 | error     | {"tax_ident_raw": "Duplicate identifier: tax_ident=267777 appears in 2 rows: 2, 3"} |                | ENTEBBE FUEL ENTERPRISES | 267777        | {}
      4 | processed | {}                                                                                  | 71426750       | KAMPALA DIGITAL ARTS     | 8040655       | {"legal_unit": "APPLIED"}
      5 | processed | {}                                                                                  | 10234244       | VICTORIA FRESH FARMS     | 364755        | {"legal_unit": "APPLIED"}
(5 rows)

\echo "Checking import job status for import_340_lu_idents"
"Checking import job status for import_340_lu_idents"
SELECT slug, state, total_rows, imported_rows, error IS NOT NULL AS has_error,
       (SELECT COUNT(*) FROM public.import_340_lu_idents_data dr WHERE dr.state = 'error') AS error_rows
FROM public.import_job
WHERE slug = 'import_340_lu_idents'
ORDER BY slug;
         slug         |  state   | total_rows | imported_rows | has_error | error_rows 
----------------------+----------+------------+---------------+-----------+------------
 import_340_lu_idents | finished |          5 |             3 | f         |          2
(1 row)

\echo Run worker processing for analytics tasks
Run worker processing for analytics tasks
CALL worker.process_tasks(p_queue => 'analytics');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | completed |     5
 import    | completed |    47
(2 rows)

\echo "Checking legal units"
"Checking legal units"
SELECT name, external_idents, unit_type
 FROM statistical_unit
 WHERE unit_type = 'legal_unit'
 ORDER BY external_idents->>'stat_ident';
         name         |                  external_idents                   | unit_type  
----------------------+----------------------------------------------------+------------
 VICTORIA FRESH FARMS | {"tax_ident": "364755", "stat_ident": "10234244"}  | legal_unit
 KAMPALA DIGITAL ARTS | {"tax_ident": "8040655", "stat_ident": "71426750"} | legal_unit
 NILE PEARL WATER     | {"tax_ident": "4672419", "stat_ident": "8204401"}  | legal_unit
(3 rows)

ROLLBACK;
