BEGIN;
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create(p_display_name => 'Test Admin', p_email => 'test.admin@statbus.org', p_statbus_role => 'admin_user'::statbus_role, p_password => 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Regular', p_email => 'test.regular@statbus.org', p_statbus_role => 'regular_user'::statbus_role, p_password => 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Restricted', p_email => 'test.restricted@statbus.org', p_statbus_role => 'restricted_user'::statbus_role, p_password => 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

CREATE OR REPLACE PROCEDURE test.remove_pg_temp_for_tx_user_switch(p_keep_tables text[] DEFAULT '{}')
LANGUAGE plpgsql
AS $remove_pg_temp_for_tx_user_switch$
DECLARE
    rec record;
    v_found_count integer := 0;
BEGIN
    RAISE DEBUG 'Running test.remove_pg_temp_for_tx_user_switch(p_keep_tables => %)...', p_keep_tables;
    -- Remove temporary cache tables used by import, as we switch user inside the *same* transaction,
    -- and the new user can not modify tables owned by the previous import.
    -- This generic loop cleans up all tables and views in the pg_temp schema, except those specified to keep.
    FOR rec IN
        SELECT
            c.relname,
            c.relkind
        FROM pg_catalog.pg_class AS c
        LEFT JOIN pg_catalog.pg_namespace AS n ON n.oid = c.relnamespace
        WHERE c.relkind IN ('r', 'p', 'v', 'm') AND n.oid = pg_my_temp_schema() -- r=table, p=partitioned, v=view, m=materialized
          AND c.relname <> ALL(p_keep_tables)
    LOOP
        v_found_count := v_found_count + 1;
        IF rec.relkind IN ('r', 'p', 'm') THEN
            RAISE DEBUG '  -> Dropping temp TABLE %', rec.relname;
            EXECUTE format('DROP TABLE IF EXISTS pg_temp.%I CASCADE', rec.relname);
        ELSIF rec.relkind = 'v' THEN
            RAISE DEBUG '  -> Dropping temp VIEW %', rec.relname;
            EXECUTE format('DROP VIEW IF EXISTS pg_temp.%I CASCADE', rec.relname);
        END IF;
    END LOOP;

    RAISE DEBUG '...finished test.remove_pg_temp_for_tx_user_switch(). Found and dropped % objects.', v_found_count;

    -- This procedure is part of the sql_saga extension and has its own cleanup logic.
    -- While the loop above handles tables/views, this call ensures any other temporary
    -- objects it creates are also cleaned up.
    CALL sql_saga.temporal_merge_drop_temp_tables();
END;
$remove_pg_temp_for_tx_user_switch$;
\echo "Setting up Statbus using the web provided examples"
"Setting up Statbus using the web provided examples"
-- A Super User configures statbus.
CALL test.set_user_from_email('test.admin@statbus.org');
\i samples/demo/getting-started.sql
-- Set the activity category standard to ISIC v4 for the demo data.
\echo "User selected the Activity Category Standard"
"User selected the Activity Category Standard"
INSERT INTO settings(activity_category_standard_id,country_id)
SELECT (SELECT id FROM activity_category_standard WHERE code = 'isic_v4')
     , (SELECT id FROM public.country WHERE iso_2 = 'UN')
ON CONFLICT (only_one_setting)
DO UPDATE SET
    activity_category_standard_id = EXCLUDED.activity_category_standard_id,
    country_id = EXCLUDED.country_id;
\echo "User uploads the demo activity categories"
"User uploads the demo activity categories"
\copy public.activity_category_available_custom(path,name) FROM 'app/public/demo/activity_custom_isic_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo regions"
"User uploads the demo regions"
\copy public.region_upload(path, name) FROM 'app/public/demo/regions_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo sectors"
"User uploads the demo sectors"
\copy public.sector_custom_only(path,name,description) FROM 'app/public/demo/sectors_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo legal forms"
"User uploads the demo legal forms"
\copy public.legal_form_custom_only(code,name) FROM 'app/public/demo/legal_forms_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
-- The demo data uses data sources that are part of the core database seed.
-- This file is included for structural consistency with other sample data sets.
SAVEPOINT before_loading_units;
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                0 |                0
(1 row)

-- Create Import Job for Legal Units
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment, time_context_ident)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_job_provided'),
    'import_340_lu_idents',
    'Import Legal Units Duplicate Idents (340_duplicate_tax_ident_small_file.sql)',
    'Import job for legal units from test/data/340_duplicate_tax_ident_small_file.csv using legal_unit_job_provided definition.',
    'Test data load (340_duplicate_tax_ident_small_file.sql)',
    'r_year_curr';
\echo "User uploads the legal units over time (via import job: import_340_lu_idents)"
"User uploads the legal units over time (via import job: import_340_lu_idents)"
\copy public.import_340_lu_idents_upload(name,stat_ident,tax_ident) FROM 'test/data/340_duplicate_tax_ident_small_file.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs
Run worker processing for import jobs
--SET client_min_messages TO DEBUG1;
CALL worker.process_tasks(p_queue => 'import');
WARNING:  [Job 16] helper_process_external_idents: Error during batch operation: duplicate key value violates unique constraint "external_ident_type_for_ident"
WARNING:  [Job 16] process_legal_unit: Unhandled error during batch operation: duplicate key value violates unique constraint "external_ident_type_for_ident"
WARNING:  [Job 16] Error processing batch: duplicate key value violates unique constraint "external_ident_type_for_ident". Context: SQL statement "
