BEGIN;
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create(p_display_name => 'Test Admin', p_email => 'test.admin@statbus.org', p_statbus_role => 'admin_user'::statbus_role, p_password => 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Regular', p_email => 'test.regular@statbus.org', p_statbus_role => 'regular_user'::statbus_role, p_password => 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Restricted', p_email => 'test.restricted@statbus.org', p_statbus_role => 'restricted_user'::statbus_role, p_password => 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

CREATE OR REPLACE PROCEDURE test.remove_pg_temp_for_tx_user_switch(p_keep_tables text[] DEFAULT '{}')
LANGUAGE plpgsql
AS $remove_pg_temp_for_tx_user_switch$
DECLARE
    rec record;
    v_found_count integer := 0;
BEGIN
    RAISE DEBUG 'Running test.remove_pg_temp_for_tx_user_switch(p_keep_tables => %)...', p_keep_tables;
    -- Remove temporary cache tables used by import, as we switch user inside the *same* transaction,
    -- and the new user can not modify tables owned by the previous import.
    -- This generic loop cleans up all tables and views in the pg_temp schema, except those specified to keep.
    FOR rec IN
        SELECT
            c.relname,
            c.relkind
        FROM pg_catalog.pg_class AS c
        LEFT JOIN pg_catalog.pg_namespace AS n ON n.oid = c.relnamespace
        WHERE c.relkind IN ('r', 'p', 'v', 'm') AND n.oid = pg_my_temp_schema() -- r=table, p=partitioned, v=view, m=materialized
          AND c.relname <> ALL(p_keep_tables)
    LOOP
        v_found_count := v_found_count + 1;
        IF rec.relkind IN ('r', 'p', 'm') THEN
            RAISE DEBUG '  -> Dropping temp TABLE %', rec.relname;
            EXECUTE format('DROP TABLE IF EXISTS pg_temp.%I CASCADE', rec.relname);
        ELSIF rec.relkind = 'v' THEN
            RAISE DEBUG '  -> Dropping temp VIEW %', rec.relname;
            EXECUTE format('DROP VIEW IF EXISTS pg_temp.%I CASCADE', rec.relname);
        END IF;
    END LOOP;

    RAISE DEBUG '...finished test.remove_pg_temp_for_tx_user_switch(). Found and dropped % objects.', v_found_count;

    -- This procedure is part of the sql_saga extension and has its own cleanup logic.
    -- While the loop above handles tables/views, this call ensures any other temporary
    -- objects it creates are also cleaned up.
    CALL sql_saga.temporal_merge_drop_temp_tables();
END;
$remove_pg_temp_for_tx_user_switch$;
\echo "Setting up Statbus using the web provided examples"
"Setting up Statbus using the web provided examples"
-- A Super User configures statbus.
CALL test.set_user_from_email('test.admin@statbus.org');
\i samples/demo/getting-started.sql
-- Set the activity category standard to ISIC v4 for the demo data.
\echo "User selected the Activity Category Standard"
"User selected the Activity Category Standard"
INSERT INTO settings(activity_category_standard_id,country_id)
SELECT (SELECT id FROM activity_category_standard WHERE code = 'isic_v4')
     , (SELECT id FROM public.country WHERE iso_2 = 'UN')
ON CONFLICT (only_one_setting)
DO UPDATE SET
    activity_category_standard_id = EXCLUDED.activity_category_standard_id,
    country_id = EXCLUDED.country_id;
\echo "User uploads the demo activity categories"
"User uploads the demo activity categories"
\copy public.activity_category_available_custom(path,name) FROM 'app/public/demo/activity_custom_isic_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo regions"
"User uploads the demo regions"
\copy public.region_upload(path, name) FROM 'app/public/demo/regions_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo sectors"
"User uploads the demo sectors"
\copy public.sector_custom_only(path,name,description) FROM 'app/public/demo/sectors_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the demo legal forms"
"User uploads the demo legal forms"
\copy public.legal_form_custom_only(code,name) FROM 'app/public/demo/legal_forms_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
-- The demo data uses data sources that are part of the core database seed.
-- This file is included for structural consistency with other sample data sets.
SAVEPOINT before_loading_units;
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                0 |                0
(1 row)

-- Create Import Job for Legal Units (Day 1)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_43_lu_day1',
    'Import LU Day 1 (43_legal_units_consecutive_days.sql)',
    'Import job for test/data/43_legal-units-day-1.csv.',
    'Test data load (43_legal_units_consecutive_days.sql)';
\echo "User uploads the legal units over time (Day 1 - via import job: import_43_lu_day1)"
"User uploads the legal units over time (Day 1 - via import job: import_43_lu_day1)"
\copy public.import_43_lu_day1_upload(valid_from,valid_to,tax_ident,stat_ident,name,birth_date,physical_region_code,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code) FROM 'test/data/43_legal-units-day-1.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs (Day 1)
Run worker processing for import jobs (Day 1)
CALL worker.process_tasks(p_queue => 'import');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     6
 import    | completed |    47
(2 rows)

\echo "Checking unit counts after import processing (Day 1)"
"Checking unit counts after import processing (Day 1)"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                1 |                1
(1 row)

\echo Run worker processing for analytics tasks (Day 1)
Run worker processing for analytics tasks (Day 1)
CALL worker.process_tasks(p_queue => 'analytics');
NOTICE:  Created btree index su_ei_tax_ident_idx for external_ident_type
NOTICE:  Created btree index su_ei_stat_ident_idx for external_ident_type
NOTICE:  Created indices for stat_definition employees
NOTICE:  Created indices for stat_definition turnover
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | completed |    27
 import    | completed |    47
(2 rows)

\echo "Checking related table counts after Day 1 analytics"
"Checking related table counts after Day 1 analytics"
SELECT
    (SELECT COUNT(*) FROM public.location) AS location_count,
    (SELECT COUNT(*) FROM public.contact) AS contact_count,
    (SELECT COUNT(*) FROM public.activity) AS activity_count;
 location_count | contact_count | activity_count 
----------------+---------------+----------------
              1 |             0 |              1
(1 row)

\echo "Checking timeline_legal_unit data after Day 1 load"
"Checking timeline_legal_unit data after Day 1 load"
SELECT unit_type
     , public.get_external_idents(unit_type, unit_id)->>'tax_ident' AS tax_ident
     , valid_from
     , valid_to
     , name
     , birth_date
     , death_date
     , search
     , primary_activity_category_path
     , activity_category_paths
     , sector_path
     , sector_code
     , sector_name
     , data_source_codes
     , legal_form_code
     , legal_form_name
     , physical_region_path
     , physical_country_iso_2
     , invalid_codes
FROM public.timeline_legal_unit
ORDER BY unit_type, unit_id, valid_from, valid_to;
 unit_type  | tax_ident  | valid_from | valid_to |       name       | birth_date | death_date |            search            | primary_activity_category_path | activity_category_paths |   sector_path   | sector_code |    sector_name     | data_source_codes | legal_form_code |       legal_form_name       | physical_region_path | physical_country_iso_2 | invalid_codes 
------------+------------+------------+----------+------------------+------------+------------+------------------------------+--------------------------------+-------------------------+-----------------+-------------+--------------------+-------------------+-----------------+-----------------------------+----------------------+------------------------+---------------
 legal_unit | 3212760144 | 2025-03-01 | infinity | NILE PEARL WATER | 2016-10-01 |            | 'nile':1 'pearl':2 'water':3 | G.47.5.2                       | {G.47.5.2}              | DOMESTIC.C.6100 | 6100        | Central government | {nlr}             | 1               | Public limited company (SA) | 2.256.13             | UG                     | 
(1 row)

-- Create Import Job for Legal Units (Day 4)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_43_lu_day4',
    'Import LU Day 4 (43_legal_units_consecutive_days.sql)',
    'Import job for test/data/43_legal-units-day-4.csv.',
    'Test data load (43_legal_units_consecutive_days.sql)';
\echo "User uploads the legal units over time (Day 4 - via import job: import_43_lu_day4)"
"User uploads the legal units over time (Day 4 - via import job: import_43_lu_day4)"
\copy public.import_43_lu_day4_upload(valid_from,valid_to,tax_ident,stat_ident,name,birth_date,physical_region_code,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code) FROM 'test/data/43_legal-units-day-4.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs (Day 4)
Run worker processing for import jobs (Day 4)
CALL worker.process_tasks(p_queue => 'import');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     6
 analytics | completed |    27
 import    | completed |    94
(3 rows)

\echo "Checking unit counts after import processing (Day 4)"
"Checking unit counts after import processing (Day 4)"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                1 |                1
(1 row)

\echo Run worker processing for analytics tasks (Day 4)
Run worker processing for analytics tasks (Day 4)
CALL worker.process_tasks(p_queue => 'analytics');
NOTICE:  Created btree index su_ei_tax_ident_idx for external_ident_type
NOTICE:  Created btree index su_ei_stat_ident_idx for external_ident_type
NOTICE:  Created indices for stat_definition employees
NOTICE:  Created indices for stat_definition turnover
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | completed |    54
 import    | completed |    94
(2 rows)

\echo "Checking related table counts after Day 4 analytics"
"Checking related table counts after Day 4 analytics"
SELECT
    (SELECT COUNT(*) FROM public.location) AS location_count,
    (SELECT COUNT(*) FROM public.contact) AS contact_count,
    (SELECT COUNT(*) FROM public.activity) AS activity_count;
 location_count | contact_count | activity_count 
----------------+---------------+----------------
              1 |             0 |              1
(1 row)

\echo "Checking timeline_legal_unit data after Day 4 load"
"Checking timeline_legal_unit data after Day 4 load"
SELECT unit_type
     , public.get_external_idents(unit_type, unit_id)->>'tax_ident' AS tax_ident
     , valid_from
     , valid_to
     , name
     , birth_date
     , death_date
     , search
     , primary_activity_category_path
     , activity_category_paths
     , sector_path
     , sector_code
     , sector_name
     , data_source_codes
     , legal_form_code
     , legal_form_name
     , physical_region_path
     , physical_country_iso_2
     , invalid_codes
FROM public.timeline_legal_unit
ORDER BY unit_type, unit_id, valid_from, valid_to;
 unit_type  | tax_ident  | valid_from | valid_to |       name       | birth_date | death_date |            search            | primary_activity_category_path | activity_category_paths |   sector_path   | sector_code |    sector_name     | data_source_codes | legal_form_code |       legal_form_name       | physical_region_path | physical_country_iso_2 | invalid_codes 
------------+------------+------------+----------+------------------+------------+------------+------------------------------+--------------------------------+-------------------------+-----------------+-------------+--------------------+-------------------+-----------------+-----------------------------+----------------------+------------------------+---------------
 legal_unit | 3212760144 | 2025-03-01 | infinity | NILE PEARL WATER | 2016-10-01 |            | 'nile':1 'pearl':2 'water':3 | G.47.5.2                       | {G.47.5.2}              | DOMESTIC.C.6100 | 6100        | Central government | {nlr}             | 1               | Public limited company (SA) | 2.256.13             | UG                     | 
(1 row)

-- Create Import Job for Legal Units (Day 3)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_43_lu_day3',
    'Import LU Day 3 (43_legal_units_consecutive_days.sql)',
    'Import job for test/data/43_legal-units-day-3.csv.',
    'Test data load (43_legal_units_consecutive_days.sql)';
\echo "User uploads the legal units over time (Day 3 - via import job: import_43_lu_day3)"
"User uploads the legal units over time (Day 3 - via import job: import_43_lu_day3)"
\copy public.import_43_lu_day3_upload(valid_from,valid_to,tax_ident,stat_ident,name,birth_date,physical_region_code,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code) FROM 'test/data/43_legal-units-day-3.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs (Day 3)
Run worker processing for import jobs (Day 3)
CALL worker.process_tasks(p_queue => 'import');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     6
 analytics | completed |    54
 import    | completed |   141
(3 rows)

\echo "Checking unit counts after import processing (Day 3)"
"Checking unit counts after import processing (Day 3)"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                1 |                1
(1 row)

\echo Run worker processing for analytics tasks (Day 3)
Run worker processing for analytics tasks (Day 3)
CALL worker.process_tasks(p_queue => 'analytics');
NOTICE:  Created btree index su_ei_tax_ident_idx for external_ident_type
NOTICE:  Created btree index su_ei_stat_ident_idx for external_ident_type
NOTICE:  Created indices for stat_definition employees
NOTICE:  Created indices for stat_definition turnover
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | completed |    81
 import    | completed |   141
(2 rows)

\echo "Checking related table counts after Day 3 analytics"
"Checking related table counts after Day 3 analytics"
SELECT
    (SELECT COUNT(*) FROM public.location) AS location_count,
    (SELECT COUNT(*) FROM public.contact) AS contact_count,
    (SELECT COUNT(*) FROM public.activity) AS activity_count;
 location_count | contact_count | activity_count 
----------------+---------------+----------------
              1 |             0 |              1
(1 row)

\echo "Checking timeline_legal_unit data after Day 3 load"
"Checking timeline_legal_unit data after Day 3 load"
SELECT unit_type
     , public.get_external_idents(unit_type, unit_id)->>'tax_ident' AS tax_ident
     , valid_from
     , valid_to
     , name
     , birth_date
     , death_date
     , search
     , primary_activity_category_path
     , activity_category_paths
     , sector_path
     , sector_code
     , sector_name
     , data_source_codes
     , legal_form_code
     , legal_form_name
     , physical_region_path
     , physical_country_iso_2
     , invalid_codes
FROM public.timeline_legal_unit
ORDER BY unit_type, unit_id, valid_from, valid_to;
 unit_type  | tax_ident  | valid_from | valid_to |       name       | birth_date | death_date |            search            | primary_activity_category_path | activity_category_paths |   sector_path   | sector_code |    sector_name     | data_source_codes | legal_form_code |       legal_form_name       | physical_region_path | physical_country_iso_2 | invalid_codes 
------------+------------+------------+----------+------------------+------------+------------+------------------------------+--------------------------------+-------------------------+-----------------+-------------+--------------------+-------------------+-----------------+-----------------------------+----------------------+------------------------+---------------
 legal_unit | 3212760144 | 2025-03-01 | infinity | NILE PEARL WATER | 2016-10-01 |            | 'nile':1 'pearl':2 'water':3 | G.47.5.2                       | {G.47.5.2}              | DOMESTIC.C.6100 | 6100        | Central government | {nlr}             | 1               | Public limited company (SA) | 2.256.13             | UG                     | 
(1 row)

ROLLBACK TO before_loading_units;
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                0 |                0
(1 row)

-- Create Import Job for Legal Units (Scenario 2 - Day 1)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_43_lu_s2_day1',
    'Import LU Scenario 2 Day 1 (43_legal_units_consecutive_days.sql)',
    'Import job for test/data/43_legal-units-day-1.csv.',
    'Test data load (43_legal_units_consecutive_days.sql)';
\echo "User uploads the legal units over time (Scenario 2 - Day 1 - via import job: import_43_lu_s2_day1)"
"User uploads the legal units over time (Scenario 2 - Day 1 - via import job: import_43_lu_s2_day1)"
\copy public.import_43_lu_s2_day1_upload(valid_from,valid_to,tax_ident,stat_ident,name,birth_date,physical_region_code,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code) FROM 'test/data/43_legal-units-day-1.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs (Scenario 2 - Day 1)
Run worker processing for import jobs (Scenario 2 - Day 1)
CALL worker.process_tasks(p_queue => 'import');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     6
 import    | completed |    47
(2 rows)

\echo "Checking unit counts after import processing (Scenario 2 - Day 1)"
"Checking unit counts after import processing (Scenario 2 - Day 1)"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                1 |                1
(1 row)

-- Create Import Job for Legal Units (Scenario 2 - Day 3)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_43_lu_s2_day3',
    'Import LU Scenario 2 Day 3 (43_legal_units_consecutive_days.sql)',
    'Import job for test/data/43_legal-units-day-3.csv.',
    'Test data load (43_legal_units_consecutive_days.sql)';
\echo "User uploads the legal units over time (Scenario 2 - Day 3 - via import job: import_43_lu_s2_day3)"
"User uploads the legal units over time (Scenario 2 - Day 3 - via import job: import_43_lu_s2_day3)"
\copy public.import_43_lu_s2_day3_upload(valid_from,valid_to,tax_ident,stat_ident,name,birth_date,physical_region_code,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code) FROM 'test/data/43_legal-units-day-3.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs (Scenario 2 - Day 3)
Run worker processing for import jobs (Scenario 2 - Day 3)
CALL worker.process_tasks(p_queue => 'import');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     6
 import    | completed |    94
(2 rows)

\echo "Checking unit counts after import processing (Scenario 2 - Day 3)"
"Checking unit counts after import processing (Scenario 2 - Day 3)"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                1 |                1
(1 row)

\echo Run worker processing for analytics tasks (Scenario 2 - Day 1 & 3)
Run worker processing for analytics tasks (Scenario 2 - Day 1 & 3)
CALL worker.process_tasks(p_queue => 'analytics');
NOTICE:  Created btree index su_ei_tax_ident_idx for external_ident_type
NOTICE:  Created btree index su_ei_stat_ident_idx for external_ident_type
NOTICE:  Created indices for stat_definition employees
NOTICE:  Created indices for stat_definition turnover
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | completed |    27
 import    | completed |    94
(2 rows)

\echo "Checking related table counts after Scenario 2 (Day 1 & 3) analytics"
"Checking related table counts after Scenario 2 (Day 1 & 3) analytics"
SELECT
    (SELECT COUNT(*) FROM public.location) AS location_count,
    (SELECT COUNT(*) FROM public.contact) AS contact_count,
    (SELECT COUNT(*) FROM public.activity) AS activity_count;
 location_count | contact_count | activity_count 
----------------+---------------+----------------
              1 |             0 |              1
(1 row)

\echo "Checking timeline_legal_unit data after Scenario 2 (Day 1 & 3) load"
"Checking timeline_legal_unit data after Scenario 2 (Day 1 & 3) load"
SELECT unit_type
     , public.get_external_idents(unit_type, unit_id)->>'tax_ident' AS tax_ident
     , valid_from
     , valid_to
     , name
     , birth_date
     , death_date
     , search
     , primary_activity_category_path
     , activity_category_paths
     , sector_path
     , sector_code
     , sector_name
     , data_source_codes
     , legal_form_code
     , legal_form_name
     , physical_region_path
     , physical_country_iso_2
     , invalid_codes
FROM public.timeline_legal_unit
ORDER BY unit_type, unit_id, valid_from, valid_to;
 unit_type  | tax_ident  | valid_from | valid_to |       name       | birth_date | death_date |            search            | primary_activity_category_path | activity_category_paths |   sector_path   | sector_code |    sector_name     | data_source_codes | legal_form_code |       legal_form_name       | physical_region_path | physical_country_iso_2 | invalid_codes 
------------+------------+------------+----------+------------------+------------+------------+------------------------------+--------------------------------+-------------------------+-----------------+-------------+--------------------+-------------------+-----------------+-----------------------------+----------------------+------------------------+---------------
 legal_unit | 3212760144 | 2025-03-01 | infinity | NILE PEARL WATER | 2016-10-01 |            | 'nile':1 'pearl':2 'water':3 | G.47.5.2                       | {G.47.5.2}              | DOMESTIC.C.6100 | 6100        | Central government | {nlr}             | 1               | Public limited company (SA) | 2.256.13             | UG                     | 
(1 row)

-- Create Import Job for Legal Units (Scenario 2 - Day 4)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_43_lu_s2_day4',
    'Import LU Scenario 2 Day 4 (43_legal_units_consecutive_days.sql)',
    'Import job for test/data/43_legal-units-day-4.csv.',
    'Test data load (43_legal_units_consecutive_days.sql)';
\echo "User uploads the legal units over time (Scenario 2 - Day 4 - via import job: import_43_lu_s2_day4)"
"User uploads the legal units over time (Scenario 2 - Day 4 - via import job: import_43_lu_s2_day4)"
\copy public.import_43_lu_s2_day4_upload(valid_from,valid_to,tax_ident,stat_ident,name,birth_date,physical_region_code,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code) FROM 'test/data/43_legal-units-day-4.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo Run worker processing for import jobs (Scenario 2 - Day 4)
Run worker processing for import jobs (Scenario 2 - Day 4)
CALL worker.process_tasks(p_queue => 'import');
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | pending   |     6
 analytics | completed |    27
 import    | completed |   141
(3 rows)

\echo "Checking unit counts after import processing (Scenario 2 - Day 4)"
"Checking unit counts after import processing (Scenario 2 - Day 4)"
SELECT
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.establishment) AS establishment_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.legal_unit) AS legal_unit_count,
    (SELECT COUNT(DISTINCT id) AS distinct_unit_count FROM public.enterprise) AS enterprise_count;
 establishment_count | legal_unit_count | enterprise_count 
---------------------+------------------+------------------
                   0 |                1 |                1
(1 row)

\echo Run worker processing for analytics tasks (Scenario 2 - Day 1, 3 & 4)
Run worker processing for analytics tasks (Scenario 2 - Day 1, 3 & 4)
CALL worker.process_tasks(p_queue => 'analytics');
NOTICE:  Created btree index su_ei_tax_ident_idx for external_ident_type
NOTICE:  Created btree index su_ei_stat_ident_idx for external_ident_type
NOTICE:  Created indices for stat_definition employees
NOTICE:  Created indices for stat_definition turnover
SELECT queue, state, count(*) FROM worker.tasks AS t JOIN worker.command_registry AS c ON t.command = c.command WHERE c.queue != 'maintenance' GROUP BY queue,state ORDER BY queue,state;
   queue   |   state   | count 
-----------+-----------+-------
 analytics | completed |    54
 import    | completed |   141
(2 rows)

\echo "Checking related table counts after Scenario 2 (Day 1, 3 & 4) analytics"
"Checking related table counts after Scenario 2 (Day 1, 3 & 4) analytics"
SELECT
    (SELECT COUNT(*) FROM public.location) AS location_count,
    (SELECT COUNT(*) FROM public.contact) AS contact_count,
    (SELECT COUNT(*) FROM public.activity) AS activity_count;
 location_count | contact_count | activity_count 
----------------+---------------+----------------
              1 |             0 |              1
(1 row)

\echo "Checking timeline_legal_unit data after Scenario 2 (Day 1, 3 & 4) load"
"Checking timeline_legal_unit data after Scenario 2 (Day 1, 3 & 4) load"
SELECT unit_type
     , public.get_external_idents(unit_type, unit_id)->>'tax_ident' AS tax_ident
     , valid_from
     , valid_to
     , name
     , birth_date
     , death_date
     , search
     , primary_activity_category_path
     , activity_category_paths
     , sector_path
     , sector_code
     , sector_name
     , data_source_codes
     , legal_form_code
     , legal_form_name
     , physical_region_path
     , physical_country_iso_2
     , invalid_codes
FROM public.timeline_legal_unit
ORDER BY unit_type, unit_id, valid_from, valid_to;
 unit_type  | tax_ident  | valid_from | valid_to |       name       | birth_date | death_date |            search            | primary_activity_category_path | activity_category_paths |   sector_path   | sector_code |    sector_name     | data_source_codes | legal_form_code |       legal_form_name       | physical_region_path | physical_country_iso_2 | invalid_codes 
------------+------------+------------+----------+------------------+------------+------------+------------------------------+--------------------------------+-------------------------+-----------------+-------------+--------------------+-------------------+-----------------+-----------------------------+----------------------+------------------------+---------------
 legal_unit | 3212760144 | 2025-03-01 | infinity | NILE PEARL WATER | 2016-10-01 |            | 'nile':1 'pearl':2 'water':3 | G.47.5.2                       | {G.47.5.2}              | DOMESTIC.C.6100 | 6100        | Central government | {nlr}             | 1               | Public limited company (SA) | 2.256.13             | UG                     | 
(1 row)

ROLLBACK;
