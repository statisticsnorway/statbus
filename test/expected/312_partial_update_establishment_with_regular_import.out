BEGIN;
\x auto
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create(p_display_name => 'Test Admin', p_email => 'test.admin@statbus.org', p_statbus_role => 'admin_user'::statbus_role, p_password => 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Regular', p_email => 'test.regular@statbus.org', p_statbus_role => 'regular_user'::statbus_role, p_password => 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Restricted', p_email => 'test.restricted@statbus.org', p_statbus_role => 'restricted_user'::statbus_role, p_password => 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

\echo "Setting up Statbus using the web provided examples"
"Setting up Statbus using the web provided examples"
-- A Super User configures statbus.
CALL test.set_user_from_email('test.admin@statbus.org');
\echo "User selected the Activity Category Standard"
"User selected the Activity Category Standard"
INSERT INTO settings(activity_category_standard_id,only_one_setting) SELECT id, true FROM activity_category_standard WHERE code = 'isic_v4' ON CONFLICT (only_one_setting) DO UPDATE SET activity_category_standard_id =(SELECT id FROM activity_category_standard WHERE code = 'isic_v4') WHERE settings.id = EXCLUDED.id;
\echo "User uploads the sample activity categories"
"User uploads the sample activity categories"
\copy public.activity_category_available_custom(path,name) FROM 'app/public/demo/activity_custom_isic_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the sample regions"
"User uploads the sample regions"
\copy public.region_upload(path, name) FROM 'app/public/demo/regions_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the sample legal forms"
"User uploads the sample legal forms"
\copy public.legal_form_custom_only(code,name) FROM 'app/public/demo/legal_forms_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "User uploads the sample sectors"
"User uploads the sample sectors"
\copy public.sector_custom_only(path,name,description) FROM 'app/public/demo/sectors_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
-- Create Import Job for Legal Units (prerequisite)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'legal_unit_source_dates'),
    'import_312_lu_wsd',
    'Import LU Demo CSV w/ dates (312)',
    'Import job for 312',
    'Test data load (312)';
\copy public.import_312_lu_wsd_upload(tax_ident,stat_ident,name,valid_from,physical_address_part1,valid_to,postal_address_part1,postal_address_part2,physical_address_part2,physical_postcode,postal_postcode,physical_address_part3,physical_postplace,postal_address_part3,postal_postplace,phone_number,landline,mobile_number,fax_number,web_address,email_address,secondary_activity_category_code,physical_latitude,physical_longitude,physical_altitude,birth_date,physical_region_code,postal_country_iso_2,physical_country_iso_2,primary_activity_category_code,legal_form_code,sector_code,employees,turnover,data_source_code,status_code,unit_size_code) FROM 'app/public/demo/legal_units_with_source_dates_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
-- Create Import Job for Establishments (prerequisite)
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'establishment_for_lu_source_dates'),
    'import_312_est_wsd',
    'Import Formal EST Demo CSV w/ dates (312)',
    'Import job for 312',
    'Test data load (312)';
\copy public.import_312_est_wsd_upload(tax_ident,stat_ident,name,physical_region_code,valid_from,valid_to,postal_country_iso_2,physical_country_iso_2,primary_activity_category_code,secondary_activity_category_code,employees,turnover,legal_unit_tax_ident,data_source_code,physical_address_part1,physical_address_part2,physical_address_part3,postal_address_part1,postal_address_part2,postal_address_part3,phone_number,mobile_number,landline,fax_number,web_address,email_address,physical_latitude,physical_longitude,physical_altitude,birth_date,unit_size_code,status_code) FROM 'app/public/demo/formal_establishments_units_with_source_dates_demo.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "Run worker processing for import jobs - Initial Load"
"Run worker processing for import jobs - Initial Load"
CALL worker.process_tasks(p_queue => 'import');
CALL worker.process_tasks(p_queue => 'analytics');
\echo "Taking snapshot of statistics before partial update (for the historical period being changed)"
"Taking snapshot of statistics before partial update (for the historical period being changed)"
CREATE TEMP TABLE stats_before_update AS
SELECT unit_type
     , jsonb_stats_summary_merge_agg(stats_summary) AS stats_summary
 FROM statistical_unit
 WHERE valid_from <= '2023-07-01'::date AND '2023-07-01'::date < valid_until
   AND unit_type = 'establishment'
 GROUP BY unit_type;
CREATE TEMP TABLE temp_source_for_update (tax_ident text, stat_ident text, turnover text, valid_from text, valid_to text);
\copy temp_source_for_update FROM 'app/public/demo/formal_establishments_turnover_update_with_source_dates.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "Checking raw stat_for_unit data BEFORE partial update"
"Checking raw stat_for_unit data BEFORE partial update"
\x off
WITH est_map AS (
    SELECT DISTINCT est.id as establishment_id, src.stat_ident
    FROM temp_source_for_update src
    JOIN public.external_ident ei ON ei.ident = src.stat_ident AND ei.type_id = (SELECT id FROM external_ident_type WHERE code = 'stat_ident')
    JOIN public.establishment est ON ei.establishment_id = est.id
    WHERE daterange(est.valid_from, est.valid_until) @> CURRENT_DATE
)
SELECT
    est_map.stat_ident,
    sfu.valid_from, sfu.valid_to,
    sd.code AS stat_code,
    sfu.value_int, sfu.value_float, sfu.value_string, sfu.value_bool
FROM public.stat_for_unit sfu
JOIN public.stat_definition sd ON sfu.stat_definition_id = sd.id
JOIN est_map ON sfu.establishment_id = est_map.establishment_id
WHERE daterange(sfu.valid_from, sfu.valid_until) && daterange('2023-01-01', '2024-01-01', '[)')
ORDER BY est_map.stat_ident::int, sd.code, sfu.valid_from;
 stat_ident | valid_from | valid_to | stat_code | value_int | value_float | value_string | value_bool 
------------+------------+----------+-----------+-----------+-------------+--------------+------------
 91000      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91000      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91001      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91001      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91002      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91002      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91003      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91003      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91004      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91004      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91005      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91005      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91006      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91006      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91007      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91007      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91008      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91008      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
 91009      | 2023-01-01 | infinity | employees |        10 |             |              | 
 91009      | 2023-01-01 | infinity | turnover  |           |        1000 |              | 
(20 rows)

\x auto
\echo "Create Import Job for Partial Establishment Update using a REGULAR import definition"
"Create Import Job for Partial Establishment Update using a REGULAR import definition"
INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
SELECT
    (SELECT id FROM public.import_definition WHERE slug = 'establishment_for_lu_source_dates'),
    'import_312_est_partial_update',
    'Import EST Partial Update (312_partial_update_establishment_with_regular_import.sql)',
    'Import job for partial establishment update using a REGULAR definition.',
    'Test data load (312_partial_update_establishment_with_regular_import.sql)';
\echo "User uploads the establishments turnover update file to a regular import job (import_312_est_partial_update)"
"User uploads the establishments turnover update file to a regular import job (import_312_est_partial_update)"
\copy public.import_312_est_partial_update_upload(tax_ident,stat_ident,turnover,valid_from,valid_to) FROM 'app/public/demo/formal_establishments_turnover_update_with_source_dates.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "Run worker processing for import jobs - Partial Update"
"Run worker processing for import jobs - Partial Update"
CALL worker.process_tasks(p_queue => 'import');
\echo "Run worker processing for analytics tasks - Partial Update"
"Run worker processing for analytics tasks - Partial Update"
CALL worker.process_tasks(p_queue => 'analytics');
\echo "Checking import data for partial update. Expecting all rows to be processed successfully."
"Checking import data for partial update. Expecting all rows to be processed successfully."
\x on
SELECT
    row_id,
    operation,
    state,
    jsonb_pretty(errors) AS errors,
    jsonb_pretty(merge_status) as merge_status
FROM public.import_312_est_partial_update_data
ORDER BY row_id;
-[ RECORD 1 ]+------------------------------------------
row_id       | 1
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 2 ]+------------------------------------------
row_id       | 2
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 3 ]+------------------------------------------
row_id       | 3
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 4 ]+------------------------------------------
row_id       | 4
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 5 ]+------------------------------------------
row_id       | 5
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 6 ]+------------------------------------------
row_id       | 6
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 7 ]+------------------------------------------
row_id       | 7
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 8 ]+------------------------------------------
row_id       | 8
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 9 ]+------------------------------------------
row_id       | 9
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }
-[ RECORD 10 ]------------------------------------------
row_id       | 10
operation    | update
state        | processed
errors       | {                                        +
             | }
merge_status | {                                        +
             |     "establishment": "SKIPPED_IDENTICAL",+
             |     "stat_turnover": "APPLIED"           +
             | }

\x auto
\echo "Checking raw stat_for_unit data AFTER partial update to verify the merge"
"Checking raw stat_for_unit data AFTER partial update to verify the merge"
\x off
SELECT
    idt.stat_ident,
    sfu.valid_from, sfu.valid_to,
    sd.code AS stat_code,
    sfu.value_int, sfu.value_float, sfu.value_string, sfu.value_bool
FROM public.stat_for_unit sfu
JOIN public.stat_definition sd ON sfu.stat_definition_id = sd.id
JOIN (
    SELECT DISTINCT establishment_id, stat_ident_raw AS stat_ident
    FROM public.import_312_est_partial_update_data
    WHERE state = 'processed' AND establishment_id IS NOT NULL
) idt ON sfu.establishment_id = idt.establishment_id
WHERE daterange(sfu.valid_from, sfu.valid_until) && daterange('2023-01-01', '2024-01-01', '[)')
ORDER BY idt.stat_ident::int, sd.code, sfu.valid_from;
 stat_ident | valid_from |  valid_to  | stat_code | value_int | value_float | value_string | value_bool 
------------+------------+------------+-----------+-----------+-------------+--------------+------------
 91000      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91000      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91000      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91000      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91001      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91001      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91001      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91001      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91002      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91002      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91002      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91002      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91003      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91003      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91003      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91003      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91004      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91004      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91004      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91004      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91005      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91005      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91005      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91005      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91006      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91006      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91006      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91006      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91007      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91007      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91007      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91007      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91008      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91008      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91008      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91008      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
 91009      | 2023-01-01 | infinity   | employees |        10 |             |              | 
 91009      | 2023-01-01 | 2023-05-31 | turnover  |           |        1000 |              | 
 91009      | 2023-06-01 | 2023-08-31 | turnover  |           |        3535 |              | 
 91009      | 2023-09-01 | infinity   | turnover  |           |        1000 |              | 
(40 rows)

\x auto
\echo "Checking resulting statistics after Partial Update. Should show turnover updated, and employees unchanged."
"Checking resulting statistics after Partial Update. Should show turnover updated, and employees unchanged."
\x off
WITH stats_after AS (
    SELECT unit_type, jsonb_stats_summary_merge_agg(stats_summary) AS stats_summary
    FROM statistical_unit
    WHERE valid_from <= '2023-07-01'::date AND '2023-07-01'::date < valid_until AND unit_type = 'establishment'
    GROUP BY unit_type
)
SELECT
    'turnover' as statistic,
    sb.stats_summary->'turnover' = sa.stats_summary->'turnover' as are_identical,
    jsonb_pretty(sb.stats_summary->'turnover') AS before,
    jsonb_pretty(sa.stats_summary->'turnover') AS after
FROM stats_after sa JOIN stats_before_update sb ON sa.unit_type = sb.unit_type
UNION ALL
SELECT
    'employees' as statistic,
    sb.stats_summary->'employees' = sa.stats_summary->'employees' as are_identical,
    jsonb_pretty(sb.stats_summary->'employees') AS before,
    jsonb_pretty(sa.stats_summary->'employees') AS after
FROM stats_after sa JOIN stats_before_update sb ON sa.unit_type = sb.unit_type;
 statistic | are_identical |                  before                   |                   after                   
-----------+---------------+-------------------------------------------+-------------------------------------------
 turnover  | f             | {                                        +| {                                        +
           |               |     "max": 1000,                         +|     "max": 3535,                         +
           |               |     "min": 20,                           +|     "min": 20,                           +
           |               |     "sum": 22154,                        +|     "sum": 47504,                        +
           |               |     "mean": 886.16,                      +|     "mean": 1900.16,                     +
           |               |     "type": "number",                    +|     "type": "number",                    +
           |               |     "count": 25,                         +|     "count": 25,                         +
           |               |     "stddev": 314.99,                    +|     "stddev": 1395.09,                   +
           |               |     "variance": 99219.22,                +|     "variance": 1946262.47,              +
           |               |     "sum_sq_diff": 2381261.36,           +|     "sum_sq_diff": 46710299.36,          +
           |               |     "coefficient_of_variation_pct": 35.55+|     "coefficient_of_variation_pct": 73.42+
           |               | }                                         | }
 employees | t             | {                                        +| {                                        +
           |               |     "max": 10,                           +|     "max": 10,                           +
           |               |     "min": 0,                            +|     "min": 0,                            +
           |               |     "sum": 223,                          +|     "sum": 223,                          +
           |               |     "mean": 8.92,                        +|     "mean": 8.92,                        +
           |               |     "type": "number",                    +|     "type": "number",                    +
           |               |     "count": 25,                         +|     "count": 25,                         +
           |               |     "stddev": 3.00,                      +|     "stddev": 3.00,                      +
           |               |     "variance": 8.99,                    +|     "variance": 8.99,                    +
           |               |     "sum_sq_diff": 215.84,               +|     "sum_sq_diff": 215.84,               +
           |               |     "coefficient_of_variation_pct": 33.62+|     "coefficient_of_variation_pct": 33.62+
           |               | }                                         | }
(2 rows)

\x auto
ROLLBACK;
