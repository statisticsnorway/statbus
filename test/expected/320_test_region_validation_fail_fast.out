SET datestyle TO 'ISO, DMY';
BEGIN;
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create(p_display_name => 'Test Admin', p_email => 'test.admin@statbus.org', p_statbus_role => 'admin_user'::statbus_role, p_password => 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Regular', p_email => 'test.regular@statbus.org', p_statbus_role => 'regular_user'::statbus_role, p_password => 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Restricted', p_email => 'test.restricted@statbus.org', p_statbus_role => 'restricted_user'::statbus_role, p_password => 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

CREATE OR REPLACE PROCEDURE test.remove_pg_temp_for_tx_user_switch(p_keep_tables text[] DEFAULT '{}')
LANGUAGE plpgsql
AS $remove_pg_temp_for_tx_user_switch$
DECLARE
    rec record;
    v_found_count integer := 0;
BEGIN
    RAISE DEBUG 'Running test.remove_pg_temp_for_tx_user_switch(p_keep_tables => %)...', p_keep_tables;
    -- Remove temporary cache tables used by import, as we switch user inside the *same* transaction,
    -- and the new user can not modify tables owned by the previous import.
    -- This generic loop cleans up all tables and views in the pg_temp schema, except those specified to keep.
    FOR rec IN
        SELECT
            c.relname,
            c.relkind
        FROM pg_catalog.pg_class AS c
        LEFT JOIN pg_catalog.pg_namespace AS n ON n.oid = c.relnamespace
        WHERE c.relkind IN ('r', 'p', 'v', 'm') AND n.oid = pg_my_temp_schema() -- r=table, p=partitioned, v=view, m=materialized
          AND c.relname <> ALL(p_keep_tables)
    LOOP
        v_found_count := v_found_count + 1;
        IF rec.relkind IN ('r', 'p', 'm') THEN
            RAISE DEBUG '  -> Dropping temp TABLE %', rec.relname;
            EXECUTE format('DROP TABLE IF EXISTS pg_temp.%I CASCADE', rec.relname);
        ELSIF rec.relkind = 'v' THEN
            RAISE DEBUG '  -> Dropping temp VIEW %', rec.relname;
            EXECUTE format('DROP VIEW IF EXISTS pg_temp.%I CASCADE', rec.relname);
        END IF;
    END LOOP;

    RAISE DEBUG '...finished test.remove_pg_temp_for_tx_user_switch(). Found and dropped % objects.', v_found_count;

    -- This procedure is part of the sql_saga extension and has its own cleanup logic.
    -- While the loop above handles tables/views, this call ensures any other temporary
    -- objects it creates are also cleaned up.
    CALL sql_saga.temporal_merge_drop_temp_tables();
END;
$remove_pg_temp_for_tx_user_switch$;
\echo "Test 320: Region Validation Fail-Fast Behavior"
"Test 320: Region Validation Fail-Fast Behavior"
\echo "Testing ACTIONABLE FAIL FAST when settings.country_id is not configured"
"Testing ACTIONABLE FAIL FAST when settings.country_id is not configured"
-- A Super User configures statbus WITHOUT settings
CALL test.set_user_from_email('test.admin@statbus.org');
-- Don't load activity categories or regions - they require settings to be configured first.
-- We only need the import_definition (which exists by default) to test analyse_location.
-- Explicitly clear settings to test fail-fast behavior
DELETE FROM public.settings;
\echo "Verify settings table is empty (no country_id configured)"
"Verify settings table is empty (no country_id configured)"
SELECT COUNT(*) as settings_count FROM public.settings;
 settings_count 
----------------
              0
(1 row)

\echo "Test 320.1: Direct test of analyse_location procedure without configured country_id - MUST FAIL FAST"
"Test 320.1: Direct test of analyse_location procedure without configured country_id - MUST FAIL FAST"
SAVEPOINT test_320_1_start;
DO $$
DECLARE 
    v_definition_id INT; 
    v_definition_slug TEXT := 'legal_unit_job_provided';
    v_job_id INT;
    error_caught BOOLEAN := FALSE;
    error_message TEXT;
BEGIN
    SELECT id INTO v_definition_id FROM public.import_definition WHERE slug = v_definition_slug;
    IF v_definition_id IS NULL THEN 
        RAISE EXCEPTION 'Import definition % not found.', v_definition_slug; 
    END IF;
    
    -- Create job WITH required time fields (this was the bug!)
    INSERT INTO public.import_job (definition_id, slug, description, edit_comment, 
                                  default_valid_from, default_valid_to)
    VALUES (v_definition_id, 'import_320_01_fail_fast_test', 'Test 320.1: Fail Fast Test', 'Test 320.1',
            '2023-01-01'::date, '2023-12-31'::date)
    RETURNING id INTO v_job_id;

    -- Try to directly call the analyse_location procedure that SHOULD fail fast
    BEGIN
        CALL import.analyse_location(v_job_id, '{[1,2)}'::int4multirange, 'physical_location');
        -- If we get here, the fail-fast did NOT work
        RAISE EXCEPTION 'FAIL-FAST VALIDATION NOT WORKING: analyse_location should fail when settings.country_id is not configured';
    EXCEPTION
        WHEN OTHERS THEN
            error_caught := TRUE;
            error_message := SQLERRM;
    END;
    
    -- Verify we caught an error
    IF NOT error_caught THEN
        RAISE EXCEPTION 'CRITICAL: analyse_location should fail when settings.country_id is not configured';
    END IF;
    
    -- Verify the error message contains the expected fail-fast text
    IF error_message NOT LIKE '%No country_id configured in settings table%' THEN
        RAISE EXCEPTION 'CRITICAL: Error message incorrect. Expected fail-fast message, got: %', error_message;
    END IF;
    
    -- Output success without job-specific details (job IDs change between runs)
    RAISE NOTICE 'Test 320.1 PASSED: analyse_location correctly fails fast when settings.country_id is not configured';
END $$;
NOTICE:  Test 320.1 PASSED: analyse_location correctly fails fast when settings.country_id is not configured
ROLLBACK TO SAVEPOINT test_320_1_start;
-- Note: Test 320.2 (invalid country_id) was removed because the FK constraint on
-- settings.country_id already provides fail-fast behavior at the schema level,
-- which is even better than runtime validation. We cannot insert an invalid
-- country_id, so the code path checking for it is unreachable in normal operation.
\echo "Test 320.2: Test analyse_location with CORRECT settings - should succeed"
"Test 320.2: Test analyse_location with CORRECT settings - should succeed"
-- Configure settings properly
INSERT INTO public.settings(activity_category_standard_id, country_id)
SELECT (SELECT id FROM activity_category_standard WHERE code = 'nace_v2.1')
     , (SELECT id FROM public.country WHERE iso_2 = 'NO');
\echo "Settings now configured correctly:"
"Settings now configured correctly:"
SELECT s.country_id, c.name as country_name 
FROM public.settings s 
JOIN public.country c ON s.country_id = c.id;
 country_id | country_name 
------------+--------------
        167 | Norway
(1 row)

DO $$
DECLARE 
    v_definition_id INT; 
    v_definition_slug TEXT := 'legal_unit_job_provided';
    v_job_id INT;
    success BOOLEAN := TRUE;
BEGIN
    SELECT id INTO v_definition_id FROM public.import_definition WHERE slug = v_definition_slug;
    
    INSERT INTO public.import_job (definition_id, slug, description, edit_comment, 
                                  default_valid_from, default_valid_to)
    VALUES (v_definition_id, 'import_320_03_success_test', 'Test 320.3: Success Test', 'Test 320.3',
            '2023-01-01'::date, '2023-12-31'::date)
    RETURNING id INTO v_job_id;

    -- This should succeed with proper configuration (even with no data to process)
    BEGIN
        CALL import.analyse_location(v_job_id, '{[1,2)}'::int4multirange, 'physical_location');
    EXCEPTION
        WHEN OTHERS THEN
            success := FALSE;
            RAISE EXCEPTION 'CRITICAL: analyse_location should succeed when settings.country_id is properly configured. Error: %', SQLERRM;
    END;
    
    -- Output success without job-specific details
    RAISE NOTICE 'Test 320.2 PASSED: analyse_location succeeds when settings.country_id is properly configured';
END $$;
NOTICE:  Test 320.2 PASSED: analyse_location succeeds when settings.country_id is properly configured
\echo "Test 320 Summary: All FAIL FAST validation tests completed"
"Test 320 Summary: All FAIL FAST validation tests completed"
SELECT 'PASS' as test_result, 'All fail-fast scenarios working correctly' as message;
 test_result |                  message                  
-------------+-------------------------------------------
 PASS        | All fail-fast scenarios working correctly
(1 row)

ROLLBACK;
