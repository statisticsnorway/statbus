BEGIN;
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create(p_display_name => 'Test Admin', p_email => 'test.admin@statbus.org', p_statbus_role => 'admin_user'::statbus_role, p_password => 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Regular', p_email => 'test.regular@statbus.org', p_statbus_role => 'regular_user'::statbus_role, p_password => 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create(p_display_name => 'Test Restricted', p_email => 'test.restricted@statbus.org', p_statbus_role => 'restricted_user'::statbus_role, p_password => 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

CREATE OR REPLACE PROCEDURE test.remove_pg_temp_for_tx_user_switch(p_keep_tables text[] DEFAULT '{}')
LANGUAGE plpgsql
AS $remove_pg_temp_for_tx_user_switch$
DECLARE
    rec record;
    v_found_count integer := 0;
BEGIN
    RAISE DEBUG 'Running test.remove_pg_temp_for_tx_user_switch(p_keep_tables => %)...', p_keep_tables;
    -- Remove temporary cache tables used by import, as we switch user inside the *same* transaction,
    -- and the new user can not modify tables owned by the previous import.
    -- This generic loop cleans up all tables and views in the pg_temp schema, except those specified to keep.
    FOR rec IN
        SELECT
            c.relname,
            c.relkind
        FROM pg_catalog.pg_class AS c
        LEFT JOIN pg_catalog.pg_namespace AS n ON n.oid = c.relnamespace
        WHERE c.relkind IN ('r', 'p', 'v', 'm') AND n.oid = pg_my_temp_schema() -- r=table, p=partitioned, v=view, m=materialized
          AND c.relname <> ALL(p_keep_tables)
    LOOP
        v_found_count := v_found_count + 1;
        IF rec.relkind IN ('r', 'p', 'm') THEN
            RAISE DEBUG '  -> Dropping temp TABLE %', rec.relname;
            EXECUTE format('DROP TABLE IF EXISTS pg_temp.%I CASCADE', rec.relname);
        ELSIF rec.relkind = 'v' THEN
            RAISE DEBUG '  -> Dropping temp VIEW %', rec.relname;
            EXECUTE format('DROP VIEW IF EXISTS pg_temp.%I CASCADE', rec.relname);
        END IF;
    END LOOP;

    RAISE DEBUG '...finished test.remove_pg_temp_for_tx_user_switch(). Found and dropped % objects.', v_found_count;

    -- This procedure is part of the sql_saga extension and has its own cleanup logic.
    -- While the loop above handles tables/views, this call ensures any other temporary
    -- objects it creates are also cleaned up.
    CALL sql_saga.temporal_merge_drop_temp_tables();
END;
$remove_pg_temp_for_tx_user_switch$;
\echo "Test 319: Import Job Failure Handling"
"Test 319: Import Job Failure Handling"
\echo "This test verifies that import jobs correctly enter 'failed' state with error details when exceptions occur."
"This test verifies that import jobs correctly enter 'failed' state with error details when exceptions occur."
-- A Super User configures statbus.
CALL test.set_user_from_email('test.admin@statbus.org');
\i samples/norway/getting-started.sql
\i samples/norway/settings.sql
INSERT INTO settings(activity_category_standard_id,country_id)
SELECT (SELECT id FROM activity_category_standard WHERE code = 'nace_v2.1')
     , (SELECT id FROM public.country WHERE iso_2 = 'NO')
ON CONFLICT (only_one_setting)
DO UPDATE SET
   activity_category_standard_id = EXCLUDED.activity_category_standard_id,
   country_id = EXCLUDED.country_id
   WHERE settings.only_one_setting = EXCLUDED.only_one_setting;
;
\i samples/norway/activity_category/activity_category_norway.sql
\copy public.activity_category_available_custom FROM 'samples/norway/activity_category/activity_category_norway.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\i samples/norway/regions/norway-regions-2024.sql
\copy public.region_upload(path, name) FROM 'samples/norway/regions/norway-regions-2024.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\i samples/norway/sector/sector_norway.sql
\copy public.sector_custom_only FROM 'samples/norway/sector/sector_norway.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\i samples/norway/legal_form/legal_form_norway.sql
\copy public.legal_form_custom_only FROM 'samples/norway/legal_form/legal_form_norway.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\i samples/norway/data_source/data_source_norway.sql
\copy public.data_source_custom (code, name) FROM 'samples/norway/data_source/data_source_norway.csv' WITH (FORMAT csv, DELIMITER ',', QUOTE '"', HEADER true);
\echo "=== Test 1: Verify 'failed' state exists in enum ==="
"=== Test 1: Verify 'failed' state exists in enum ==="
SELECT unnest(enum_range(NULL::public.import_job_state)) AS state
ORDER BY state;
       state        
--------------------
 waiting_for_upload
 upload_completed
 preparing_data
 analysing_data
 waiting_for_review
 approved
 rejected
 processing_data
 failed
 finished
(10 rows)

\echo "=== Test 2: Verify constraint on failed state requiring error ==="
"=== Test 2: Verify constraint on failed state requiring error ==="
-- The constraint should prevent failed state without error
SELECT conname, pg_get_constraintdef(oid)
FROM pg_constraint
WHERE conrelid = 'public.import_job'::regclass
  AND conname = 'import_job_failed_requires_error';
             conname              |                          pg_get_constraintdef                          
----------------------------------+------------------------------------------------------------------------
 import_job_failed_requires_error | CHECK (((state <> 'failed'::import_job_state) OR (error IS NOT NULL)))
(1 row)

\echo "=== Test 3: Create an import job and verify initial state ==="
"=== Test 3: Create an import job and verify initial state ==="
DO $$
DECLARE
    v_definition_id INT;
BEGIN
    SELECT id INTO v_definition_id FROM public.import_definition WHERE slug = 'legal_unit_source_dates';
    INSERT INTO public.import_job (definition_id, slug, description, note, edit_comment)
    VALUES (v_definition_id, 'import_319_failure_test', 'Test 319: Failure handling test', 'Testing error handling', 'Test 319');
END $$;
SELECT slug, state, error IS NOT NULL AS has_error
FROM public.import_job
WHERE slug = 'import_319_failure_test';
          slug           |       state        | has_error 
-------------------------+--------------------+-----------
 import_319_failure_test | waiting_for_upload | f
(1 row)

\echo "=== Test 4: Upload data with invalid region code (will trigger region code collision on second region) ==="
"=== Test 4: Upload data with invalid region code (will trigger region code collision on second region) ==="
-- First, let's add duplicate regions that will cause a collision during import lookup
-- This simulates the Albania issue where AL.01 and 01 both have code '01'
-- Load some data to import
INSERT INTO public.import_319_failure_test_upload(
    valid_from, valid_to, tax_ident, name, birth_date, death_date,
    physical_address_part1, physical_postcode, physical_postplace, physical_region_code, physical_country_iso_2,
    primary_activity_category_code, sector_code, legal_form_code
) VALUES
('2020-01-01', '2020-12-31', '319000001', 'Test Company 1', '2020-01-01', NULL,
 'Address 1', '1234', 'Oslo', '0301', 'NO',
 '01.110', '2100', 'AS');
\echo "Check upload row count"
"Check upload row count"
SELECT COUNT(*) AS upload_row_count FROM public.import_319_failure_test_upload;
 upload_row_count 
------------------
                1
(1 row)

\echo "=== Test 5: Process the import job (should succeed for valid data) ==="
"=== Test 5: Process the import job (should succeed for valid data) ==="
CALL worker.process_tasks(p_queue => 'import');
\echo "Check job status after processing valid data"
"Check job status after processing valid data"
SELECT slug, state, total_rows, imported_rows, error IS NOT NULL AS has_error
FROM public.import_job
WHERE slug = 'import_319_failure_test';
          slug           |  state   | total_rows | imported_rows | has_error 
-------------------------+----------+------------+---------------+-----------
 import_319_failure_test | finished |          1 |             1 | f
(1 row)

\echo "=== Test 6: Manually test that failed state requires error ==="
"=== Test 6: Manually test that failed state requires error ==="
-- Try to set state to 'failed' without setting error (should fail)
SAVEPOINT test_constraint;
\set ON_ERROR_STOP off
UPDATE public.import_job
SET state = 'failed', error = NULL
WHERE slug = 'import_319_failure_test';
ERROR:  new row for relation "import_job" violates check constraint "import_job_failed_requires_error"
\set ON_ERROR_STOP on
ROLLBACK TO test_constraint;
\echo "Verify job state is still unchanged after failed constraint violation"
"Verify job state is still unchanged after failed constraint violation"
SELECT slug, state, error IS NOT NULL AS has_error
FROM public.import_job
WHERE slug = 'import_319_failure_test';
          slug           |  state   | has_error 
-------------------------+----------+-----------
 import_319_failure_test | finished | f
(1 row)

\echo "=== Test 7: Manually set job to failed with error (should succeed) ==="
"=== Test 7: Manually set job to failed with error (should succeed) ==="
UPDATE public.import_job
SET state = 'failed', error = '{"test_error": "Simulated failure for testing"}'
WHERE slug = 'import_319_failure_test';
SELECT slug, state, error IS NOT NULL AS has_error, error
FROM public.import_job
WHERE slug = 'import_319_failure_test';
          slug           | state  | has_error |                      error                      
-------------------------+--------+-----------+-------------------------------------------------
 import_319_failure_test | failed | t         | {"test_error": "Simulated failure for testing"}
(1 row)

\echo "=== Test 8: Verify state transitions are valid ==="
"=== Test 8: Verify state transitions are valid ==="
-- Reset state to 'finished' to test other transitions
UPDATE public.import_job
SET state = 'finished', error = NULL
WHERE slug = 'import_319_failure_test';
SELECT slug, state, error IS NOT NULL AS has_error
FROM public.import_job
WHERE slug = 'import_319_failure_test';
          slug           |  state   | has_error 
-------------------------+----------+-----------
 import_319_failure_test | finished | f
(1 row)

\echo "Import job failure handling tests completed successfully"
"Import job failure handling tests completed successfully"
ROLLBACK;
