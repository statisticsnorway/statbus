NOTICE:  identifier "pg_regress/67_test_batch_insert_or_update_with_valid_from_trigger" will be truncated to "pg_regress/67_test_batch_insert_or_update_with_valid_from_trigg"
BEGIN;
\i test/setup.sql
-- While the datestyle is set for the database, the pg_regress tool sets the MDY format
-- to ensure consistent date formatting, so we must manually override this
SET datestyle TO 'ISO, DMY';
\if :{?DEBUG}
SET client_min_messages TO debug1;
\else
SET client_min_messages TO NOTICE;
\endif
-- Create temporary function to execute queries as system user
CREATE OR REPLACE FUNCTION test.sudo_exec(
    sql text,
    OUT results jsonb
) RETURNS jsonb
SECURITY DEFINER LANGUAGE plpgsql AS $sudo_exec$
DECLARE
    result_rows jsonb;
BEGIN
    -- Check if the SQL starts with common DDL keywords
    IF sql ~* '^\s*(CREATE|DROP|ALTER|TRUNCATE|GRANT|REVOKE|ANALYZE)' THEN
        -- For DDL statements, execute directly
        EXECUTE sql;
        results := '[]'::jsonb;
    ELSE
        -- For DML/queries, wrap in a SELECT to capture results
        EXECUTE format('
            SELECT COALESCE(
                jsonb_agg(row_to_json(t)),
                ''[]''::jsonb
            )
            FROM (%s) t',
            sql
        ) INTO result_rows;
        results := result_rows;
    END IF;
END;
$sudo_exec$;
-- Grant execute to public since this is for testing
GRANT EXECUTE ON FUNCTION test.sudo_exec(text) TO PUBLIC;
\echo Add users for testing purposes
Add users for testing purposes
SELECT * FROM public.user_create('test.admin@statbus.org', 'admin_user'::statbus_role, 'Admin#123!');
         email          |  password  
------------------------+------------
 test.admin@statbus.org | Admin#123!
(1 row)

SELECT * FROM public.user_create('test.regular@statbus.org', 'regular_user'::statbus_role, 'Regular#123!');
          email           |   password   
--------------------------+--------------
 test.regular@statbus.org | Regular#123!
(1 row)

SELECT * FROM public.user_create('test.restricted@statbus.org', 'restricted_user'::statbus_role, 'Restricted#123!');
            email            |    password     
-----------------------------+-----------------
 test.restricted@statbus.org | Restricted#123!
(1 row)

\echo '----------------------------------------------------------------------------'
----------------------------------------------------------------------------
\echo 'Test: import.batch_insert_or_update_generic_valid_time_table (with valid_from trigger)'
Test: import.batch_insert_or_update_generic_valid_time_table (with valid_from trigger)
\echo '----------------------------------------------------------------------------'
----------------------------------------------------------------------------
SET client_min_messages TO NOTICE; -- Reverted for cleaner output
CREATE SCHEMA IF NOT EXISTS batch_test_update_vf; 
CREATE SEQUENCE IF NOT EXISTS batch_test_update_vf.batch_upsert_target_id_seq;
NOTICE:  Granted USAGE on new sequence batch_test_update_vf.batch_upsert_target_id_seq to authenticated
CREATE TABLE batch_test_update_vf.batch_upsert_target (
    id INT NOT NULL DEFAULT nextval('batch_test_update_vf.batch_upsert_target_id_seq'),
    valid_from DATE NOT NULL, -- Added for this test
    valid_after DATE NOT NULL, 
    valid_to DATE NOT NULL,    
    value_a TEXT,
    value_b INT,
    value_c TEXT, 
    updated_on DATE, -- Changed from updated_at TIMESTAMPTZ
    edit_comment TEXT,
    PRIMARY KEY (id, valid_after) 
);
CREATE TRIGGER trg_target_synchronize_valid_from_after
    BEFORE INSERT OR UPDATE ON batch_test_update_vf.batch_upsert_target
    FOR EACH ROW EXECUTE FUNCTION public.synchronize_valid_from_after();
CREATE TABLE batch_test_update_vf.batch_upsert_source (
    row_id BIGSERIAL PRIMARY KEY,
    founding_row_id BIGINT,
    target_id INT,
    valid_after DATE NOT NULL, 
    valid_to DATE,             
    value_a TEXT,
    value_b INT,
    value_c TEXT, 
    updated_on DATE, -- Changed from updated_at TIMESTAMPTZ
    edit_comment TEXT
);
\set target_schema 'batch_test_update_vf'
\set target_table 'batch_upsert_target'
\set source_schema 'batch_test_update_vf'
\set source_table 'batch_upsert_source'
-- \set source_row_id_col 'row_id' -- Removed
\set unique_cols '[ "value_a" ]'
-- \set temporal_cols '{valid_after, valid_to}' -- Removed
\set ephemeral_cols '{edit_comment, updated_on}'
\set id_col 'id'
CREATE OR REPLACE FUNCTION batch_test_update_vf.show_target_table(p_filter_id INT DEFAULT NULL)
RETURNS TABLE (id INT, valid_from DATE, valid_after DATE, valid_to DATE, value_a TEXT, value_b INT, value_c TEXT, updated_on DATE, edit_comment TEXT) AS $$
BEGIN
    IF p_filter_id IS NULL THEN
        RETURN QUERY SELECT tgt.id, tgt.valid_from, tgt.valid_after, tgt.valid_to, tgt.value_a, tgt.value_b, tgt.value_c, tgt.updated_on, tgt.edit_comment 
                     FROM batch_test_update_vf.batch_upsert_target tgt ORDER BY tgt.id, tgt.valid_after;
    ELSE
        RETURN QUERY SELECT tgt.id, tgt.valid_from, tgt.valid_after, tgt.valid_to, tgt.value_a, tgt.value_b, tgt.value_c, tgt.updated_on, tgt.edit_comment 
                     FROM batch_test_update_vf.batch_upsert_target tgt WHERE tgt.id = p_filter_id ORDER BY tgt.valid_after;
    END IF;
END;
$$ LANGUAGE plpgsql;
-- Scenario 1: Initial Insert
\echo 'Scenario 1: Initial Insert'
Scenario 1: Initial Insert
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, NULL, '2023-12-31', '2024-12-31', 'A', 10, 'Initial C1', '2024-01-15', 'Initial A'); -- row_id=1, founding_row_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => :'unique_cols'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table();
 id | valid_from | valid_after |  valid_to  | value_a | value_b |  value_c   | updated_on | edit_comment 
----+------------+-------------+------------+---------+---------+------------+------------+--------------
  1 | 2024-01-01 | 2023-12-31  | 2024-12-31 | A       |      10 | Initial C1 | 2024-01-15 | Initial A
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 2: Update existing - Full Overlap, Non-Null Update
\echo 'Scenario 2: Update existing - Full Overlap, Non-Null Update'
Scenario 2: Update existing - Full Overlap, Non-Null Update
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-12-31', 'A', 10, 'Original C', '2024-01-10', 'Original'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-12-31', 'A', 20, 'Updated C', '2024-01-15', 'Update B and C'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); 
 id | valid_from | valid_after |  valid_to  | value_a | value_b |  value_c  | updated_on |  edit_comment  
----+------------+-------------+------------+---------+---------+-----------+------------+----------------
  1 | 2024-01-01 | 2023-12-31  | 2024-12-31 | A       |      20 | Updated C | 2024-01-15 | Update B and C
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 3: Update existing - Full Overlap, Partial Null Update (value_b is NULL in source)
\echo 'Scenario 3: Update existing - Full Overlap, Partial Null Update'
Scenario 3: Update existing - Full Overlap, Partial Null Update
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-12-31', 'A', 10, 'Original C', '2024-01-10', 'Original'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-12-31', 'A', NULL, 'Updated C by partial null', '2024-01-15', 'Update C, B is null in source'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); 
 id | valid_from | valid_after |  valid_to  | value_a | value_b |          value_c          | updated_on |         edit_comment          
----+------------+-------------+------------+---------+---------+---------------------------+------------+-------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-12-31 | A       |      10 | Updated C by partial null | 2024-01-15 | Update C, B is null in source
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 4: Update existing - Inside Different (Split with Update)
\echo 'Scenario 4: Update existing - Inside Different (Split with Update)'
Scenario 4: Update existing - Inside Different (Split with Update)
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-12-31', 'A', 10, 'Original C', '2024-01-10', 'Original Jan-Dec'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2024-03-31', '2024-08-31', 'A', 20, NULL, '2024-01-15', 'Update Apr-Aug, C is null'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); 
 id | valid_from | valid_after |  valid_to  | value_a | value_b |  value_c   | updated_on |       edit_comment        
----+------------+-------------+------------+---------+---------+------------+------------+---------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-03-31 | A       |      10 | Original C | 2024-01-10 | Original Jan-Dec
  1 | 2024-04-01 | 2024-03-31  | 2024-08-31 | A       |      20 | Original C | 2024-01-15 | Update Apr-Aug, C is null
  1 | 2024-09-01 | 2024-08-31  | 2024-12-31 | A       |      10 | Original C | 2024-01-10 | Original Jan-Dec
(3 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 5: No data change, only temporal adjustment (adjacent equivalent merge)
\echo 'Scenario 5: No data change, only temporal adjustment (adjacent equivalent merge)'
Scenario 5: No data change, only temporal adjustment (adjacent equivalent merge)
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-06-30', 'A', 10, 'C val', '2024-01-10', 'First half'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2024-06-30', '2024-12-31', 'A', 10, 'C val', '2024-01-15', 'Second half'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect updated_on from source, edit_comment from source
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on | edit_comment 
----+------------+-------------+------------+---------+---------+---------+------------+--------------
  1 | 2024-01-01 | 2023-12-31  | 2024-12-31 | A       |      10 | C val   | 2024-01-15 | Second half
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 6: Source overlaps start of existing, data different
\echo 'Scenario 6: Source overlaps start of existing, data different'
Scenario 6: Source overlaps start of existing, data different
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-03-01', '2024-02-29', '2024-10-31', 'A', 10, 'Original C', '2024-01-10', 'Existing Mid-Year'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-05-31', 'A', 20, 'Updated C by Source Overlap Start', '2024-01-15', 'Source Overlaps Start'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  | value_a | value_b |              value_c              | updated_on |     edit_comment      
----+------------+-------------+------------+---------+---------+-----------------------------------+------------+-----------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-02-29 | A       |      20 | Updated C by Source Overlap Start | 2024-01-15 | Source Overlaps Start
  1 | 2024-03-01 | 2024-02-29  | 2024-05-31 | A       |      20 | Updated C by Source Overlap Start | 2024-01-15 | Source Overlaps Start
  1 | 2024-06-01 | 2024-05-31  | 2024-10-31 | A       |      10 | Original C                        | 2024-01-10 | Existing Mid-Year
(3 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 7: Source overlaps end of existing, data different
\echo 'Scenario 7: Source overlaps end of existing, data different'
Scenario 7: Source overlaps end of existing, data different
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-08-31', 'A', 10, 'Original C', '2024-01-10', 'Existing Early-Mid Year'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2024-05-31', '2024-12-31', 'A', 30, 'Updated C by Source Overlap End', '2024-01-15', 'Source Overlaps End'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  | value_a | value_b |             value_c             | updated_on |      edit_comment       
----+------------+-------------+------------+---------+---------+---------------------------------+------------+-------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-05-31 | A       |      10 | Original C                      | 2024-01-10 | Existing Early-Mid Year
  1 | 2024-06-01 | 2024-05-31  | 2024-08-31 | A       |      30 | Updated C by Source Overlap End | 2024-01-15 | Source Overlaps End
  1 | 2024-09-01 | 2024-08-31  | 2024-12-31 | A       |      30 | Updated C by Source Overlap End | 2024-01-15 | Source Overlaps End
(3 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 8: Existing is contained within source, data different
\echo 'Scenario 8: Existing is contained within source, data different'
Scenario 8: Existing is contained within source, data different
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-03-01', '2024-02-29', '2024-08-31', 'A', 10, 'Original C', '2024-01-10', 'Existing Mid-Period'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-12-31', 'A', 40, 'Updated C by Source Contains Existing', '2024-01-15', 'Source Contains Existing'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  | value_a | value_b |                value_c                | updated_on |       edit_comment       
----+------------+-------------+------------+---------+---------+---------------------------------------+------------+--------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-02-29 | A       |      40 | Updated C by Source Contains Existing | 2024-01-15 | Source Contains Existing
  1 | 2024-03-01 | 2024-02-29  | 2024-08-31 | A       |      40 | Updated C by Source Contains Existing | 2024-01-15 | Source Contains Existing
  1 | 2024-09-01 | 2024-08-31  | 2024-12-31 | A       |      40 | Updated C by Source Contains Existing | 2024-01-15 | Source Contains Existing
(3 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 9: Existing is contained within source, data equivalent
\echo 'Scenario 9: Existing is contained within source, data equivalent'
Scenario 9: Existing is contained within source, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-03-01', '2024-02-29', '2024-08-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Mid-Period, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-12-31', 'A', 10, 'Same C', '2024-01-15', 'Source Contains Existing, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |            edit_comment             
----+------------+-------------+------------+---------+---------+---------+------------+-------------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-12-31 | A       |      10 | Same C  | 2024-01-15 | Source Contains Existing, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 10: Source overlaps start of existing, data equivalent
\echo 'Scenario 10: Source overlaps start of existing, data equivalent'
Scenario 10: Source overlaps start of existing, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-03-01', '2024-02-29', '2024-10-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Mid-Year, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-05-31', 'A', 10, 'Same C', '2024-01-15', 'Source Overlaps Start, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |           edit_comment           
----+------------+-------------+------------+---------+---------+---------+------------+----------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-10-31 | A       |      10 | Same C  | 2024-01-15 | Source Overlaps Start, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 11: Source overlaps end of existing, data equivalent
\echo 'Scenario 11: Source overlaps end of existing, data equivalent'
Scenario 11: Source overlaps end of existing, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-08-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Early-Mid Year, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2024-05-31', '2024-12-31', 'A', 10, 'Same C', '2024-01-15', 'Source Overlaps End, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |          edit_comment          
----+------------+-------------+------------+---------+---------+---------+------------+--------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-12-31 | A       |      10 | Same C  | 2024-01-15 | Source Overlaps End, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 12: Source starts existing, data different
\echo 'Scenario 12: Source starts existing, data different'
Scenario 12: Source starts existing, data different
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-10-31', 'A', 10, 'Original C', '2024-01-10', 'Existing Full Year'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-05-31', 'A', 50, 'Updated C by Source Starts Existing', '2024-01-15', 'Source Starts Existing'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  | value_a | value_b |               value_c               | updated_on |      edit_comment      
----+------------+-------------+------------+---------+---------+-------------------------------------+------------+------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-05-31 | A       |      50 | Updated C by Source Starts Existing | 2024-01-15 | Source Starts Existing
  1 | 2024-06-01 | 2024-05-31  | 2024-10-31 | A       |      10 | Original C                          | 2024-01-10 | Existing Full Year
(2 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 13: Existing starts source, data different
\echo 'Scenario 13: Existing starts source, data different'
Scenario 13: Existing starts source, data different
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-05-31', 'A', 10, 'Original C', '2024-01-10', 'Existing Shorter Period'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-10-31', 'A', 60, 'Updated C by Existing Starts Source', '2024-01-15', 'Existing Starts Source'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  | value_a | value_b |               value_c               | updated_on |      edit_comment      
----+------------+-------------+------------+---------+---------+-------------------------------------+------------+------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-05-31 | A       |      60 | Updated C by Existing Starts Source | 2024-01-15 | Existing Starts Source
  1 | 2024-06-01 | 2024-05-31  | 2024-10-31 | A       |      60 | Updated C by Existing Starts Source | 2024-01-15 | Existing Starts Source
(2 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 14: Existing finishes source, data different
\echo 'Scenario 14: Existing finishes source, data different'
Scenario 14: Existing finishes source, data different
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-04-01', '2024-03-31', '2024-10-31', 'A', 10, 'Original C', '2024-01-10', 'Existing Later Part'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-10-31', 'A', 70, 'Updated C by Existing Finishes Source', '2024-01-15', 'Existing Finishes Source'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  | value_a | value_b |                value_c                | updated_on |       edit_comment       
----+------------+-------------+------------+---------+---------+---------------------------------------+------------+--------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-03-31 | A       |      70 | Updated C by Existing Finishes Source | 2024-01-15 | Existing Finishes Source
  1 | 2024-04-01 | 2024-03-31  | 2024-10-31 | A       |      70 | Updated C by Existing Finishes Source | 2024-01-15 | Existing Finishes Source
(2 rows)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 15: Source starts existing, data equivalent
\echo 'Scenario 15: Source starts existing, data equivalent'
Scenario 15: Source starts existing, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-10-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Full Year, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-05-31', 'A', 10, 'Same C', '2024-01-15', 'Source Starts Existing, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |           edit_comment            
----+------------+-------------+------------+---------+---------+---------+------------+-----------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-10-31 | A       |      10 | Same C  | 2024-01-15 | Source Starts Existing, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 16: Existing starts source, data equivalent
\echo 'Scenario 16: Existing starts source, data equivalent'
Scenario 16: Existing starts source, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-05-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Shorter, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-10-31', 'A', 10, 'Same C', '2024-01-15', 'Existing Starts Source, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |           edit_comment            
----+------------+-------------+------------+---------+---------+---------+------------+-----------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-10-31 | A       |      10 | Same C  | 2024-01-15 | Existing Starts Source, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 17: Source finishes existing, data equivalent
\echo 'Scenario 17: Source finishes existing, data equivalent'
Scenario 17: Source finishes existing, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', '2024-10-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Full Year, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2024-03-31', '2024-10-31', 'A', 10, 'Same C', '2024-01-15', 'Source Finishes Existing, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |            edit_comment             
----+------------+-------------+------------+---------+---------+---------+------------+-------------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-10-31 | A       |      10 | Same C  | 2024-01-15 | Source Finishes Existing, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 18: Existing finishes source, data equivalent
\echo 'Scenario 18: Existing finishes source, data equivalent'
Scenario 18: Existing finishes source, data equivalent
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-04-01', '2024-03-31', '2024-10-31', 'A', 10, 'Same C', '2024-01-10', 'Existing Later Part, Same Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2023-12-31', '2024-10-31', 'A', 10, 'Same C', '2024-01-15', 'Existing Finishes Source, Same Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); -- Expect ephemeral from source (updated_on='2024-01-15')
 id | valid_from | valid_after |  valid_to  | value_a | value_b | value_c | updated_on |            edit_comment             
----+------------+-------------+------------+---------+---------+---------+------------+-------------------------------------
  1 | 2024-01-01 | 2023-12-31  | 2024-10-31 | A       |      10 | Same C  | 2024-01-15 | Existing Finishes Source, Same Data
(1 row)

TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 19: Yearly Override with Equivalent Core Data (Update Strategy)
\echo 'Scenario 19: Yearly Override with Equivalent Core Data (Update Strategy)'
Scenario 19: Yearly Override with Equivalent Core Data (Update Strategy)
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2024-01-01', '2023-12-31', 'infinity', 'EQ_DATA', 100, 'C_VAL', '2024-01-10', 'Year 1 Import Data'); 
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2024-12-31', 'infinity', 'EQ_DATA', 100, 'C_VAL', '2025-01-15', 'Year 2 Import Data'); -- founding_row_id=target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1); 
 id | valid_from | valid_after | valid_to | value_a | value_b | value_c | updated_on |    edit_comment    
----+------------+-------------+----------+---------+---------+---------+------------+--------------------
  1 | 2024-01-01 | 2023-12-31  | infinity | EQ_DATA |     100 | C_VAL   | 2025-01-15 | Year 2 Import Data
(1 row)

-- Expected (NEW): 1 row, ephemeral data (edit_comment, updated_on) updated from source.
-- Row 1: id=1, vf=2024-01-01, va=2023-12-31, vt=infinity, value_a='EQ_DATA', value_b=100, value_c='C_VAL', 
--        updated_on='2025-01-15', comment='Year 2 Import Data'
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target; ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- New Scenario: Multiple Edits to Same New Entity in One Batch (founding_row_id cache test)
\echo 'Scenario N1: Multiple Edits to Same New Entity in One Batch (founding_row_id cache test)'
Scenario N1: Multiple Edits to Same New Entity in One Batch (founding_row_id cache test)
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
DELETE FROM batch_test_update_vf.batch_upsert_target;
ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(101, NULL, '2023-01-01', '2023-06-30', 'MultiEditNewVF_U', 10, 'C_First_U', '2023-01-15', 'First part new VF_U'), -- row_id=1
(101, NULL, '2023-07-01', '2023-12-31', 'MultiEditNewVF_U', 20, 'C_Second_U', '2023-07-15', 'Second part new VF_U, values changed'); -- row_id=2
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => :'unique_cols'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
) ORDER BY source_row_id;
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
             2 |                  1 | SUCCESS | 
(2 rows)

SELECT * FROM batch_test_update_vf.show_target_table();
 id | valid_from | valid_after |  valid_to  |     value_a      | value_b |  value_c   | updated_on |             edit_comment             
----+------------+-------------+------------+------------------+---------+------------+------------+--------------------------------------
  1 | 2023-01-02 | 2023-01-01  | 2023-06-30 | MultiEditNewVF_U |      10 | C_First_U  | 2023-01-15 | First part new VF_U
  1 | 2023-07-02 | 2023-07-01  | 2023-12-31 | MultiEditNewVF_U |      20 | C_Second_U | 2023-07-15 | Second part new VF_U, values changed
(2 rows)

-- Expected: A single new ID (e.g., 1) should be created for 'MultiEditNewVF_U'.
-- Two rows for this ID due to different value_b/c in different periods.
-- ID (e.g. 1): (MultiEditNewVF_U, 10, C_First_U) valid_from='2023-01-02', valid_after='2023-01-01', valid_to='2023-06-30', updated_on='2023-01-15'
-- ID (e.g. 1): (MultiEditNewVF_U, 20, C_Second_U) valid_from='2023-07-02', valid_after='2023-07-01', valid_to='2023-12-31', updated_on='2023-07-15'
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target;
ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- New Scenario: Rolling Infinity Updates - Equivalent Core Data
\echo 'Scenario N2: Rolling Infinity Updates - Equivalent Core Data (Update Strategy)'
Scenario N2: Rolling Infinity Updates - Equivalent Core Data (Update Strategy)
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
DELETE FROM batch_test_update_vf.batch_upsert_target;
ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Step 1: Insert initial record with valid_to = infinity
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(201, NULL, '2022-12-31', 'infinity', 'RollingInfVF_U', 100, 'C_Initial_U', '2023-01-01', 'Initial Infinity VF_U');
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => :'unique_cols'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table();
 id | valid_from | valid_after | valid_to |    value_a     | value_b |   value_c   | updated_on |     edit_comment      
----+------------+-------------+----------+----------------+---------+-------------+------------+-----------------------
  1 | 2023-01-01 | 2022-12-31  | infinity | RollingInfVF_U |     100 | C_Initial_U | 2023-01-01 | Initial Infinity VF_U
(1 row)

-- Expected: One row for new ID (e.g. 1), (RollingInfVF_U, 100, C_Initial_U), vf='2023-01-01', va='2022-12-31', vt='infinity', updated_on='2023-01-01'
-- Step 2: Update with a new record that meets the previous one, same core data, new ephemeral data
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(201, 1, '2023-12-31', 'infinity', 'RollingInfVF_U', 100, 'C_Initial_U', '2024-01-01', 'Update Ephemeral for Infinity VF_U'); -- Assumes ID 1 was created
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB,
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after | valid_to |    value_a     | value_b |   value_c   | updated_on |            edit_comment            
----+------------+-------------+----------+----------------+---------+-------------+------------+------------------------------------
  1 | 2023-01-01 | 2022-12-31  | infinity | RollingInfVF_U |     100 | C_Initial_U | 2024-01-01 | Update Ephemeral for Infinity VF_U
(1 row)

-- Expected: One row for ID 1, (RollingInfVF_U, 100, C_Initial_U), vf='2023-01-01', va='2022-12-31', vt='infinity', updated_on='2024-01-01'
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE; DELETE FROM batch_test_update_vf.batch_upsert_target;
ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Scenario 20: Fix Verification (Update Strategy) - Sequential Equivalent Segments with Infinity
\echo 'Scenario 20: Fix Verification (Update Strategy) - Sequential Equivalent Segments with Infinity'
Scenario 20: Fix Verification (Update Strategy) - Sequential Equivalent Segments with Infinity
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
DELETE FROM batch_test_update_vf.batch_upsert_target;
ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Step 20.1: Manually insert initial record for Year 1 (ends before infinity to set a base)
\echo 'Step 20.1: Insert Year 1 data (e.g., 2021)'
Step 20.1: Insert Year 1 data (e.g., 2021)
INSERT INTO batch_test_update_vf.batch_upsert_target (id, valid_from, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, '2021-01-01', '2020-12-31', '2021-12-31', 'FixVerifyUpdateInf', 100, 'C_FixVerify', '2021-01-10', 'Year 1 Data');
SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after |  valid_to  |      value_a       | value_b |   value_c   | updated_on | edit_comment 
----+------------+-------------+------------+--------------------+---------+-------------+------------+--------------
  1 | 2021-01-01 | 2020-12-31  | 2021-12-31 | FixVerifyUpdateInf |     100 | C_FixVerify | 2021-01-10 | Year 1 Data
(1 row)

-- Expected: 1 row for ID 1: (FixVerifyUpdateInf,100,C_FixVerify) vf='2021-01-01', va='2020-12-31', vt='2021-12-31', updated_on='2021-01-10', comment='Year 1 Data'
-- Step 20.2: Process Year 2 data (meets Year 1, equivalent core, new ephemeral, ends infinity)
\echo 'Step 20.2: Process Year 2 data (meets Year 1, equivalent core, new ephemeral, ends infinity)'
Step 20.2: Process Year 2 data (meets Year 1, equivalent core, new ephemeral, ends infinity)
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2021-12-31', 'infinity', 'FixVerifyUpdateInf', 100, 'C_FixVerify', '2022-01-10', 'Year 2 Data'); -- target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB, -- ID is provided
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after | valid_to |      value_a       | value_b |   value_c   | updated_on | edit_comment 
----+------------+-------------+----------+--------------------+---------+-------------+------------+--------------
  1 | 2021-01-01 | 2020-12-31  | infinity | FixVerifyUpdateInf |     100 | C_FixVerify | 2022-01-10 | Year 2 Data
(1 row)

-- Expected: 1 row for ID 1:
-- vf='2021-01-01', va='2020-12-31', vt='infinity'
-- value_a='FixVerifyUpdateInf', value_b=100, value_c='C_FixVerify'
-- updated_on='2022-01-10', comment='Year 2 Data'
-- Step 20.3: Process Year 3 data (meets Year 2 period, equivalent core, new ephemeral, ends infinity)
\echo 'Step 20.3: Process Year 3 data (meets Year 2, equivalent core, new ephemeral, ends infinity)'
Step 20.3: Process Year 3 data (meets Year 2, equivalent core, new ephemeral, ends infinity)
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
INSERT INTO batch_test_update_vf.batch_upsert_source (founding_row_id, target_id, valid_after, valid_to, value_a, value_b, value_c, updated_on, edit_comment) VALUES
(1, 1, '2022-12-31', 'infinity', 'FixVerifyUpdateInf', 100, 'C_FixVerify', '2023-01-10', 'Year 3 Data'); -- target_id=1
SELECT * FROM import.batch_insert_or_update_generic_valid_time_table(
    p_target_schema_name           => :'target_schema',
    p_target_table_name            => :'target_table',
    p_source_schema_name           => :'source_schema',
    p_source_table_name            => :'source_table',
    p_unique_columns               => '[]'::JSONB, -- ID is provided
    p_ephemeral_columns            => :'ephemeral_cols'::TEXT[],
    p_id_column_name               => :'id_col',
    p_generated_columns_override   => NULL
);
 source_row_id | upserted_record_id | status  | error_message 
---------------+--------------------+---------+---------------
             1 |                  1 | SUCCESS | 
(1 row)

SELECT * FROM batch_test_update_vf.show_target_table(1);
 id | valid_from | valid_after | valid_to |      value_a       | value_b |   value_c   | updated_on | edit_comment 
----+------------+-------------+----------+--------------------+---------+-------------+------------+--------------
  1 | 2021-01-01 | 2020-12-31  | infinity | FixVerifyUpdateInf |     100 | C_FixVerify | 2023-01-10 | Year 3 Data
(1 row)

-- Expected: 1 row for ID 1:
-- vf='2021-01-01', va='2020-12-31', vt='infinity'
-- value_a='FixVerifyUpdateInf', value_b=100, value_c='C_FixVerify'
-- updated_on='2023-01-10', comment='Year 3 Data'
TRUNCATE batch_test_update_vf.batch_upsert_source RESTART IDENTITY CASCADE;
DELETE FROM batch_test_update_vf.batch_upsert_target;
ALTER SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq RESTART WITH 1;
-- Cleanup
DROP FUNCTION batch_test_update_vf.show_target_table(INT);
DROP TABLE batch_test_update_vf.batch_upsert_source;
DROP TABLE batch_test_update_vf.batch_upsert_target; -- Trigger will be dropped with the table
DROP SEQUENCE batch_test_update_vf.batch_upsert_target_id_seq;
DROP SCHEMA batch_test_update_vf CASCADE;
SET client_min_messages TO NOTICE; -- Revert client_min_messages at the end
ROLLBACK;
