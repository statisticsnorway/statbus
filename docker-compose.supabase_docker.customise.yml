# Adapt Supabase.
services:
  auth:
    depends_on:
      db:
        condition: service_healthy
  kong:
    # Expose API endpoint
    ports:
      - ${SUPABASE_BIND_ADDRESS}:8000/tcp
  rest:
    environment:
      # Enable group by counting for getting the available filter values with counts
      # for statistical_unit
      # Available with the query `select=count(),primary_activity_category_id`
      # and `select=count(),physical_region_id`
      # and uses indices for this.
      PGRST_DB_AGGREGATES_ENABLED: true
    depends_on:
      db:
        condition: service_healthy
  db:
    # Use a custom build with sql_saga extension for temporal tables.
    image: ghcr.io/veridit/supabase_postgres:c035263a
    #image: veridit/supabase_postgres:latest
    # Prevent the database from using too much memory.
    shm_size: 4g
    mem_limit: 4G
    mem_reservation: 2G
    ports:
      - 127.0.0.1:${DB_PUBLIC_LOCALHOST_PORT}:5432
    volumes:
      # Make all files available for running tests.
      - ..:/statbus
    environment:
      # Update to match https://github.com/supabase/postgres/blob/develop/Dockerfile-16#L214
      # for the new setup where postres is not the default user.
      POSTGRES_USER: supabase_admin
      POSTGRES_DB: postgres
    command:
      - postgres
      - -c
      - config_file=/etc/postgresql/postgresql.conf
      - -c
      - log_min_messages=fatal # prevents Realtime polling queries from appearing in logs
      - -c # Disable synchronous_commit to avoid waiting for WAL flush to disk, increasing performance at the cost of durability.
      - synchronous_commit=off
      - -c # Delay WAL writes to disk by 500ms to batch more transactions and reduce disk I/O pressure.
      - wal_writer_delay=500ms
      - -c # Increase the time between checkpoints to 15 minutes, reducing I/O spikes by having fewer checkpoints.
      - checkpoint_timeout=15min
      - -c # Allow checkpoints to be spread over 90% of the time between checkpoints, reducing their performance impact.
      - checkpoint_completion_target=0.9
      - -c # Allocate 1GB of shared memory buffers for PostgreSQL to cache more data in RAM, reducing the need for disk reads.
      - shared_buffers=1GB
      - -c # Set the work memory to 1GB, allowing larger operations (e.g., sorts, joins) to use more memory and avoid temporary disk usage.
      - work_mem=1GB
      - -c # Allocate 1GB for maintenance operations such as VACUUM and CREATE INDEX, improving the performance of these operations.
      - maintenance_work_mem=1GB
      - -c # Set WAL buffers to 64MB, allowing more WAL data to be stored in memory before being written to disk, reducing write frequency.
      - wal_buffers=64MB
      - -c # Allocate memory for temporary tables operations
      - temp_buffers=256MB
      - -c # Increase stack depth for complex recursive queries (7MB is below the 7680kB limit)
      - max_stack_depth=7MB
      - -c # Help query planner make better decisions
      - effective_cache_size=3GB
      - -c # Allow hash-based operations to use more memory
      - hash_mem_multiplier=2.0
      - -c # Log slow queries for debugging
      - log_min_duration_statement=1000
  storage:
    # Override the address of the healthcheck from localhost that resolves to ::1 (IPv6)
    # instead of the correct 127.0.0.1 (IPv4) that storage listens to, as it binds
    # to 0.0.0.0 (IPv4) and not ::1 (IPv6).
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://127.0.0.1:5000/status",
        ]
  studio:
    # Override the address of the healthcheck from localhost that resolves to 127.0.0.1 (IPv4) that studio
    # does *NOT* listen to, as it binds to the exposed interface only!!
    # Use the docker lookup of studio to the assigned IP address instead.
    healthcheck:
      # Increase timeout for beign able to do first time install of curl.
      timeout: 10s
      interval: 15s
      retries: 3
      test:
        # Use bash script for efficient health checking:
        # 1. Avoids loading Node.js which was causing high I/O
        # 2. Installs curl only if needed (first run)
        # 3. Uses lightweight curl for subsequent health checks
        # 4. Uses internal Docker DNS resolution with 'studio' hostname
        [
          "CMD",
          "/bin/bash",
          "-c",
          "which curl || (apt-get update && apt-get install -y curl) && curl -f http://studio:3000/api/profile || exit 1",
        ]
